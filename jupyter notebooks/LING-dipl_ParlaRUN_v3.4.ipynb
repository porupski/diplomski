{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i41M-W8THOQu"
   },
   "source": [
    "# Running ParlaSpeechHR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESbAn_EQRYyT"
   },
   "source": [
    "## [0] Start here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:01:50.242260Z",
     "iopub.status.busy": "2024-06-16T17:01:50.242260Z",
     "iopub.status.idle": "2024-06-16T17:01:50.245456Z",
     "shell.execute_reply": "2024-06-16T17:01:50.245456Z",
     "shell.execute_reply.started": "2024-06-16T17:01:50.242260Z"
    }
   },
   "outputs": [],
   "source": [
    "choose_lm_model = False\n",
    "\n",
    "google_colabbing = False\n",
    "debug_printing = True\n",
    "\n",
    "testing_asr = True # if False, cuts audio into chunks\n",
    "shuffle_transcript = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:01:50.569941Z",
     "iopub.status.busy": "2024-06-16T17:01:50.569941Z",
     "iopub.status.idle": "2024-06-16T17:01:50.574272Z",
     "shell.execute_reply": "2024-06-16T17:01:50.574272Z",
     "shell.execute_reply.started": "2024-06-16T17:01:50.569941Z"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1718358967568,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "hXbSzO_hGn2a",
    "outputId": "93214040-342d-47cd-b2d5-ef7bf1304c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3.4\n"
     ]
    }
   ],
   "source": [
    "work_version_num = 3.4\n",
    "word_version_preffix = \"\"\n",
    "\n",
    "if choose_lm_model == True:\n",
    "    word_version_suffix = \"_lm\"\n",
    "else:\n",
    "    word_version_suffix = \"\"\n",
    "work_version = f\"{word_version_preffix}v{work_version_num}{word_version_suffix}\"\n",
    "\n",
    "print(work_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [INFO ABOUT MACHINE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:10:09.511233Z",
     "iopub.status.busy": "2024-06-16T12:10:09.511233Z",
     "iopub.status.idle": "2024-06-16T12:10:09.513830Z",
     "shell.execute_reply": "2024-06-16T12:10:09.513830Z",
     "shell.execute_reply.started": "2024-06-16T12:10:09.511233Z"
    }
   },
   "outputs": [],
   "source": [
    "### NEED TO REINSTALL PYTORCH WITH CUDA ENABLED AND TRY AGAIN I GUESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:10:09.703821Z",
     "iopub.status.busy": "2024-06-16T12:10:09.703821Z",
     "iopub.status.idle": "2024-06-16T12:10:11.121046Z",
     "shell.execute_reply": "2024-06-16T12:10:11.121046Z",
     "shell.execute_reply.started": "2024-06-16T12:10:09.703821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor: 11th Gen Intel(R) Core(TM) i5-11600 @ 2.80GHz\n",
      "Architecture: X86_64\n",
      "Cores: 12\n"
     ]
    }
   ],
   "source": [
    "import cpuinfo\n",
    "\n",
    "info = cpuinfo.get_cpu_info()\n",
    "\n",
    "print(\"Processor:\", info[\"brand_raw\"])\n",
    "print(\"Architecture:\", info[\"arch\"])\n",
    "print(\"Cores:\", info[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:10:11.123038Z",
     "iopub.status.busy": "2024-06-16T12:10:11.122040Z",
     "iopub.status.idle": "2024-06-16T12:10:12.136676Z",
     "shell.execute_reply": "2024-06-16T12:10:12.136676Z",
     "shell.execute_reply.started": "2024-06-16T12:10:11.123038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: NVIDIA CUDA\n",
      "Vendor: NVIDIA Corporation\n",
      "Version: OpenCL 1.2 CUDA 11.1.96\n",
      "\n",
      "Device: GeForce GTX 760\n",
      "Type: ALL | GPU\n",
      "Max Compute Units: 6\n",
      "Max Work Item Dimensions: 3\n",
      "Max Work Group Size: 1024\n",
      "Max Clock Frequency: 1150 MHz\n",
      "Global Memory Size: 4.00 GB\n",
      "Local Memory Size: 48.00 KB\n",
      "Max Memory Allocation Size: 1.00 GB\n",
      "OpenCL Version: OpenCL C 1.2 \n",
      "Driver Version: 456.71\n",
      "Platform: Intel(R) OpenCL HD Graphics\n",
      "Vendor: Intel(R) Corporation\n",
      "Version: OpenCL 3.0 \n",
      "\n",
      "Device: Intel(R) UHD Graphics 750\n",
      "Type: ALL | GPU\n",
      "Max Compute Units: 32\n",
      "Max Work Item Dimensions: 3\n",
      "Max Work Group Size: 256\n",
      "Max Clock Frequency: 1300 MHz\n",
      "Global Memory Size: 6.32 GB\n",
      "Local Memory Size: 64.00 KB\n",
      "Max Memory Allocation Size: 3.16 GB\n",
      "OpenCL Version: OpenCL C 1.2 \n",
      "Driver Version: 30.0.101.1273\n",
      "Platform: Intel(R) OpenCL\n",
      "Vendor: Intel(R) Corporation\n",
      "Version: OpenCL 3.0 WINDOWS\n",
      "\n",
      "Device: 11th Gen Intel(R) Core(TM) i5-11600 @ 2.80GHz\n",
      "Type: ALL | CPU\n",
      "Max Compute Units: 12\n",
      "Max Work Item Dimensions: 3\n",
      "Max Work Group Size: 8192\n",
      "Max Clock Frequency: 2800 MHz\n",
      "Global Memory Size: 15.80 GB\n",
      "Local Memory Size: 32.00 KB\n",
      "Max Memory Allocation Size: 7.90 GB\n",
      "OpenCL Version: OpenCL C 3.0 \n",
      "Driver Version: 2023.16.6.0.28_042959\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyopencl\n",
    "\n",
    "import pyopencl as cl\n",
    "\n",
    "# Get a list of all available platforms\n",
    "platforms = cl.get_platforms()\n",
    "\n",
    "for platform in platforms:\n",
    "    print(f\"Platform: {platform.name}\")\n",
    "    print(f\"Vendor: {platform.vendor}\")\n",
    "    print(f\"Version: {platform.version}\")\n",
    "\n",
    "    # Get a list of all available devices for the current platform\n",
    "    devices = platform.get_devices()\n",
    "    for device in devices:\n",
    "        print(f\"\\nDevice: {device.name}\")\n",
    "        print(f\"Type: {cl.device_type.to_string(device.type)}\")\n",
    "        print(f\"Max Compute Units: {device.max_compute_units}\")\n",
    "        print(f\"Max Work Item Dimensions: {device.max_work_item_dimensions}\")\n",
    "        print(f\"Max Work Group Size: {device.max_work_group_size}\")\n",
    "        print(f\"Max Clock Frequency: {device.max_clock_frequency} MHz\")\n",
    "        print(f\"Global Memory Size: {device.global_mem_size / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"Local Memory Size: {device.local_mem_size / 1024:.2f} KB\")\n",
    "        print(f\"Max Memory Allocation Size: {device.max_mem_alloc_size / (1024 ** 3):.2f} GB\")\n",
    "        print(f\"OpenCL Version: {device.opencl_c_version}\")\n",
    "        print(f\"Driver Version: {device.driver_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU VERSION:\n",
    "Device: 11th Gen Intel(R) Core(TM) i5-11600 @ 2.80GHz\r\n",
    "Type: ALL | CPU\r\n",
    "Max Compute Units: 12\r\n",
    "Max Work Item Dimensions: 3\r\n",
    "Max Work Group Size: 8192\r\n",
    "Max Clock Frequency: 2800 MHz\r\n",
    "Global Memory Size: 15.80 GB\r\n",
    "Local Memory Size: 32.00 KB\r\n",
    "Max Memory Allocation Size: 7.90 GB\r\n",
    "OpenCL Version: OpenCL C 3.0 \r\n",
    "Driver Version: 2023.16.6.0.28_042959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T12:08:46.818196Z",
     "iopub.status.busy": "2024-06-16T12:08:46.817198Z",
     "iopub.status.idle": "2024-06-16T12:08:53.088954Z",
     "shell.execute_reply": "2024-06-16T12:08:53.088954Z",
     "shell.execute_reply.started": "2024-06-16T12:08:46.818196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.3.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, mkl, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, optimum, sentence-transformers, torchaudio, torchvision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\pandas-2.1.4.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torchvision\n",
      "Version: 0.15.2a0\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
      "Requires: numpy, pillow, requests, torch\n",
      "Required-by: sentence-transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\pandas-2.1.4.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torchaudio\n",
      "Version: 2.3.1\n",
      "Summary: An audio package for PyTorch\n",
      "Home-page: https://github.com/pytorch/audio\n",
      "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
      "Author-email: soumith@pytorch.org\n",
      "License: \n",
      "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
      "Requires: torch\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\pandas-2.1.4.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "!pip show torch\n",
    "!pip show torchvision\n",
    "!pip show torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T18:17:22.441732Z",
     "iopub.status.busy": "2024-06-15T18:17:22.440735Z",
     "iopub.status.idle": "2024-06-15T18:17:22.446005Z",
     "shell.execute_reply": "2024-06-15T18:17:22.446005Z",
     "shell.execute_reply.started": "2024-06-15T18:17:22.441732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available or GPU is too old.\n",
      "device set to: CPU (cpu)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 3.7:\n",
    "    device = torch.device(\"cuda:0\")  # Use GPU\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use CPU\n",
    "    print(\"CUDA not available or GPU is too old.\")\n",
    "    print(f\"device set to: CPU ({device})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0vOINi-RVG-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [1] Install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T16:06:56.342183Z",
     "iopub.status.busy": "2024-06-16T16:06:56.341187Z",
     "iopub.status.idle": "2024-06-16T16:07:01.418052Z",
     "shell.execute_reply": "2024-06-16T16:07:01.418052Z",
     "shell.execute_reply.started": "2024-06-16T16:06:56.341187Z"
    },
    "executionInfo": {
     "elapsed": 4872,
     "status": "ok",
     "timestamp": 1718358985791,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "Y-1HeiN2HWYh",
    "outputId": "3e4fc84f-371f-455b-cafb-e8d2fcd8837a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good. Every essential package is present to make the code work.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"transformers: All good.\")\n",
    "except ImportError:\n",
    "    !pip install transformers\n",
    "    print(\"transformers: Installed.\")\n",
    "\n",
    "try:\n",
    "    import pydub\n",
    "    print(\"pydub: All good.\")\n",
    "except ImportError:\n",
    "    !pip install pydub\n",
    "    print(\"pydub: Installed.\")\n",
    "\n",
    "try:\n",
    "    import torchaudio\n",
    "    print(\"torchaudio: All good.\")\n",
    "except ImportError:\n",
    "    !pip install torchaudio\n",
    "    print(\"torchaudio: Installed.\")\n",
    "\n",
    "try:\n",
    "    import pyctcdecode\n",
    "    print(\"pyctcdecode: All good.\")\n",
    "except ImportError:\n",
    "    !pip install pyctcdecode\n",
    "    print(\"pyctcdecode: Installed.\")\n",
    "\n",
    "try:\n",
    "    import jiwer\n",
    "    print(\"jiwer: All good.\")\n",
    "except ImportError:\n",
    "    !pip install jiwer\n",
    "    print(\"jiwer: Installed.\")\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    print(\"nltk: All good.\")\n",
    "except ImportError:\n",
    "    !pip install nltk\n",
    "    print(\"nltk: Installed.\")\n",
    "\n",
    "try:\n",
    "    from fuzzywuzzy import fuzz\n",
    "    print(\"fuzzywuzzy: All good.\")\n",
    "except ImportError:   \n",
    "    !pip install fuzzywuzzy\n",
    "    print(\"fuzzywuzzy: Installed.\")\n",
    "\n",
    "clear_output(wait=True) # clean the mess\n",
    "print(f\"All good. Every essential package is present to make the code work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T16:07:01.419047Z",
     "iopub.status.busy": "2024-06-16T16:07:01.419047Z",
     "iopub.status.idle": "2024-06-16T16:07:01.422988Z",
     "shell.execute_reply": "2024-06-16T16:07:01.422988Z",
     "shell.execute_reply.started": "2024-06-16T16:07:01.419047Z"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1718358989147,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "QpXmeQkhHSMy",
    "outputId": "18d66a32-7b49-4cac-ed0e-2f4d4bb4c771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good. kenlm is present to make the LM model.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import kenlm\n",
    "    print(f\"All good. kenlm is present to make the LM model.\")\n",
    "except ImportError:\n",
    "    !pip install https://github.com/kpu/kenlm/archive/master.zip # requires runtime restart\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9) # restart automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bkH_9mFRi5n"
   },
   "source": [
    "## [2] Defining all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:01:54.763118Z",
     "iopub.status.busy": "2024-06-16T17:01:54.753543Z",
     "iopub.status.idle": "2024-06-16T17:01:54.765570Z",
     "shell.execute_reply": "2024-06-16T17:01:54.765570Z",
     "shell.execute_reply.started": "2024-06-16T17:01:54.763118Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718358968575,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "PnFUfYq5HPsy"
   },
   "outputs": [],
   "source": [
    "path_to_pshr_raw_audio_data = r\"D:\\ParlaSpeech-HR.v1.0\\raw\"\n",
    "path_to_pshr_raw_jsonl = r\"D:\\ParlaSpeech-HR.v1.0\\ParlaSpeech-HR.v1.0.jsonl\"\n",
    "\n",
    "path_to_pshr_models = r\"D:\\ASR\\ParlaspeechHR\"\n",
    "path_to_pshr_wav2vec2_l = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\"\n",
    "path_to_pshr_wav2vec2_l_lm = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavic-hr-lm\"\n",
    "\n",
    "test_audio_path = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavic-hr-lm\\nela_film_review.ogg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:01:55.321921Z",
     "iopub.status.busy": "2024-06-16T17:01:55.321921Z",
     "iopub.status.idle": "2024-06-16T17:01:55.324757Z",
     "shell.execute_reply": "2024-06-16T17:01:55.324757Z",
     "shell.execute_reply.started": "2024-06-16T17:01:55.321921Z"
    },
    "executionInfo": {
     "elapsed": 2210,
     "status": "ok",
     "timestamp": 1718358996758,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "aDFTbiSfHyu9",
    "outputId": "828f1e69-1cba-46eb-a187-0ad01bc92414"
   },
   "outputs": [],
   "source": [
    "# # Mount gdrive and place path (private, no download)\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# model_file_path = \"/content/drive/MyDrive/pytorch/wav2vec2-large-slavic-hr\"\n",
    "# output_folder = \"/content/drive/MyDrive/pytorch/wav2vec2-large-slavic-hr/temp\"\n",
    "\n",
    "# model_file_path_lm = \"/content/drive/MyDrive/pytorch/wav2vec2-large-slavic-hr-lm\"\n",
    "# output_folder_lm = \"/content/drive/MyDrive/pytorch/wav2vec2-large-slavic-hr-lm/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKlYE54RRsUH"
   },
   "source": [
    "## [3] Downloading wav2vec2 (plain or WithLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:01:59.371285Z",
     "iopub.status.busy": "2024-06-16T17:01:59.371285Z",
     "iopub.status.idle": "2024-06-16T17:01:59.378299Z",
     "shell.execute_reply": "2024-06-16T17:01:59.378299Z",
     "shell.execute_reply.started": "2024-06-16T17:01:59.371285Z"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1718359439487,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "65WVbDBfIgUw",
    "outputId": "16f08152-bfbd-4c0f-d16a-334b4fdaef48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running localy, good luck\n",
      "\n",
      "Using model from path: D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\n"
     ]
    }
   ],
   "source": [
    "# Download HF repository manually and place path (public, ~2GB download)\n",
    "import os\n",
    "\n",
    "\n",
    "if google_colabbing == True:\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    if choose_lm_model == False:\n",
    "      # Check if the directory exists\n",
    "      if not os.path.exists(\"/content/wav2vec2-large-slavic-parlaspeech-hr\"):\n",
    "          # Clone the repository if it doesn't exist\n",
    "          !git clone https://huggingface.co/classla/wav2vec2-large-slavic-parlaspeech-hr\n",
    "          os.makedirs(\"/content/wav2vec2-large-slavic-parlaspeech-hr/temp\", exist_ok=True)\n",
    "      else:\n",
    "          print(f\"wav2vec2-parlaspeech-hr already exists.\")\n",
    "    \n",
    "      model_file_path = \"/content/wav2vec2-large-slavic-parlaspeech-hr\"\n",
    "      print(f\"\\nUsing model from path: {model_file_path}\")\n",
    "    \n",
    "    else:\n",
    "      # Check if the directory exists\n",
    "      if not os.path.exists(\"/content/pytorch/wav2vec2-large-slavic-hr-lm\"):\n",
    "          # Clone the repository if it doesn't exist\n",
    "          !git clone https://huggingface.co/classla/wav2vec2-large-slavic-parlaspeech-hr-lm\n",
    "          os.makedirs(\"/content/wav2vec2-large-slavic-parlaspeech-hr-lm/temp\", exist_ok=True)\n",
    "      else:\n",
    "          print(f\"wav2vec2-parlaspeech-hr-lm already exists.\")\n",
    "    \n",
    "      model_file_path = \"/content/pytorch/wav2vec2-large-slavic-hr-lm\"\n",
    "      print(f\"\\nUsing model from path: {model_file_path}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Running localy, good luck\")\n",
    "    \n",
    "    if choose_lm_model == False:\n",
    "        model_file_path = path_to_pshr_wav2vec2_l\n",
    "    else: \n",
    "        model_file_path = path_to_pshr_wav2vec2_l_lm\n",
    "    print(f\"\\nUsing model from path: {model_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay3Tr6dBR0gn"
   },
   "source": [
    "## [4] Initilize the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:03.194373Z",
     "iopub.status.busy": "2024-06-16T17:02:03.194373Z",
     "iopub.status.idle": "2024-06-16T17:02:10.968481Z",
     "shell.execute_reply": "2024-06-16T17:02:10.968481Z",
     "shell.execute_reply.started": "2024-06-16T17:02:03.194373Z"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1718361529289,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "KbCTLV-yHiZh",
    "outputId": "97943b4f-e296-416a-e5b5-d25330207698"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\torch\\cuda\\__init__.py:184: UserWarning: \n",
      "    Found GPU0 GeForce GTX 760 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available or GPU is too old.\n",
      "device set to: CPU (cpu)\n",
      "device: cpu\n",
      "tokenizer0 not found. Making tokenizer0...\n",
      "feature_extractor0 not found. Making feature_extractor0...\n",
      "processor0 not found. Making processor0...\n",
      "model0 not found. Making model0... device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ProcessorWithLM,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2Config,\n",
    "    AutoModelForCTC,\n",
    "    AutoProcessor,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "import kenlm\n",
    "from pyctcdecode import BeamSearchDecoderCTC, build_ctcdecoder\n",
    "\n",
    "# Set device as gpu, default = cpu\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 3.7:\n",
    "    device = torch.device(\"cuda:0\")  # Use GPU\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use CPU\n",
    "    print(\"CUDA not available or GPU is too old.\")\n",
    "    print(f\"device set to: CPU ({device})\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "\n",
    "config_file_path = os.path.join(model_file_path, \"config.json\")\n",
    "config_json = Wav2Vec2Config.from_json_file(config_file_path)\n",
    "\n",
    "\n",
    "if choose_lm_model == False:\n",
    "  # Make the tokenizer\n",
    "  if 'tokenizer0' not in globals():\n",
    "    print(f\"tokenizer0 not found. Making tokenizer0...\")\n",
    "    tokenizer0 = Wav2Vec2CTCTokenizer(model_file_path + \"/vocab.json\",\n",
    "                                    unk_token=\"[UNK]\",\n",
    "                                    pad_token=\"[PAD]\",\n",
    "                                    word_delimiter_token=\"|\")\n",
    "  else:\n",
    "    print(f\"tokenizer0 exists.\")\n",
    "\n",
    "  # Make feature_extractor manually taken from preprocessor_config.json\n",
    "  if 'feature_extractor0' not in globals():\n",
    "    print(f\"feature_extractor0 not found. Making feature_extractor0...\")\n",
    "    feature_extractor0 = Wav2Vec2FeatureExtractor(feature_size=1,\n",
    "                                                sampling_rate=16000,\n",
    "                                                padding_value=0.0,\n",
    "                                                do_normalize=True,\n",
    "                                                return_attention_mask=True)\n",
    "  else:\n",
    "    print(f\"feature_extractor0 exists.\")\n",
    "\n",
    "  # Make the processor\n",
    "  if 'processor0' not in globals():\n",
    "    print(f\"processor0 not found. Making processor0...\")\n",
    "    processor0 = Wav2Vec2Processor.from_pretrained(model_file_path)\n",
    "  else:\n",
    "      print(\"processor0 exists.\")\n",
    "\n",
    "  # Make the model\n",
    "  if 'model0' not in globals():\n",
    "    print(f\"model0 not found. Making model0... device {device}\")\n",
    "    model0 = Wav2Vec2ForCTC.from_pretrained(model_file_path,\n",
    "                                            config=config_json).to(device)\n",
    "  else:\n",
    "    print(f\"model0 exists. device {device}\")\n",
    "  model0.to(device)\n",
    "  model0.eval()\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    processor0lm = AutoProcessor.from_pretrained(model_file_path)\n",
    "\n",
    "    vocab_lm_path = os.path.join(model_file_path, \"vocab.json\")\n",
    "    #print(vocab_lm_path)\n",
    "    tokenizer0lm = Wav2Vec2CTCTokenizer(\n",
    "        vocab_lm_path,\n",
    "        unk_token=\"[UNK]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        word_delimiter_token=\"|\",\n",
    "        )\n",
    "    feature_extractor0lm = Wav2Vec2FeatureExtractor(\n",
    "        feature_size=1,\n",
    "        sampling_rate=16000,\n",
    "        padding_value=0.0,\n",
    "        do_normalize=True,\n",
    "        return_attention_mask=True,\n",
    "        )\n",
    "    model0lm = AutoModelForCTC.from_pretrained(model_file_path).to(device)\n",
    "    \n",
    "  # # Make the tokenizer\n",
    "  # if 'tokenizer0lm' not in globals():\n",
    "  #   print(f\"tokenizer0lm not found. Making tokenizer0lm...\")\n",
    "  #   vocab_lm_path = os.path.join(model_file_path, \"vocab.json\")\n",
    "  #   tokenizer0lm = Wav2Vec2CTCTokenizer(vocab_lm_path,\n",
    "  #                                   unk_token=\"[UNK]\",\n",
    "  #                                   pad_token=\"[PAD]\",\n",
    "  #                                   word_delimiter_token=\"|\")\n",
    "  # else:\n",
    "  #   print(f\"tokenizer0lm exists.\")\n",
    "\n",
    "  # # Make feature_extractor manually taken from preprocessor_config.json\n",
    "  # if 'feature_extractor0lm' not in globals():\n",
    "  #   print(f\"feature_extractor0lm not found. Making feature_extractor0lm...\")\n",
    "  #   feature_extractor0lm = Wav2Vec2FeatureExtractor(feature_size=1,\n",
    "  #                                                   sampling_rate=16000,\n",
    "  #                                                   padding_value=0.0,\n",
    "  #                                                   do_normalize=True,\n",
    "  #                                                   return_attention_mask=True)\n",
    "  # else:\n",
    "  #   print(f\"feature_extractor0lm exists.\")\n",
    "\n",
    "  # # Make the processor\n",
    "  # if 'processor0lm' not in globals():\n",
    "  #   print(f\"processor0lm not found. Making processor0lm...\")\n",
    "  #   processor0lm = Wav2Vec2ProcessorWithLM.from_pretrained(model_file_path)\n",
    "  # else:\n",
    "  #   print(\"processor0lm exists.\")\n",
    "\n",
    "  # # Make the model\n",
    "  # if 'model0lm' not in globals():\n",
    "  #   print(f\"model0lm not found. Making model0lm...  device {device}\")\n",
    "  #   model0lm = Wav2Vec2ForCTC.from_pretrained(model_file_path,\n",
    "  #                                             config=config_file_path).to(device)\n",
    "  # else:\n",
    "  #     print(f\"model0lm exists. device {device}\")\n",
    "\n",
    "    \n",
    "    model0lm.to(device)\n",
    "    model0lm.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8eTi90-R7E_"
   },
   "source": [
    "## [5] Define cutting down into temp chunks (now with DYNAMICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:13.683418Z",
     "iopub.status.busy": "2024-06-16T17:02:13.683418Z",
     "iopub.status.idle": "2024-06-16T17:02:14.219447Z",
     "shell.execute_reply": "2024-06-16T17:02:14.219447Z",
     "shell.execute_reply.started": "2024-06-16T17:02:13.683418Z"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1718360508968,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "15EPOU2EL7Xu",
    "outputId": "a676d1d2-e0d8-4746-a7d6-d1519087be8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is debug_printing on? True\n",
      "\n",
      "Transcription function defined and active: \n",
      "Splitting audio in: 20s segments (dynamically). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_CHUNK = 20\n",
    "target_sr=16000\n",
    "\n",
    "SILENCE_THRESHOLD = 0.01  # Threshold to detect silence\n",
    "MIN_SILENCE_LENGTH = 0.5  # Minimum length of silence to be considered a split point in seconds\n",
    "\n",
    "\n",
    "print(f\"Is debug_printing on? {debug_printing}\\n\")\n",
    "\n",
    "### PROCESSING ENGINE ###\n",
    "\n",
    "def process_transcribe(input_file):\n",
    "    \n",
    "        # Begin processing:\n",
    "        speech, sample_rate = torchaudio.load(input_file)\n",
    "\n",
    "        # Check if resampling is needed\n",
    "        if sample_rate != target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
    "            speech = resampler(speech)\n",
    "\n",
    "        # Process the speech with the processor\n",
    "        input_values = processor0(speech, sampling_rate=target_sr, return_tensors=\"pt\").input_values.to(device)\n",
    "\n",
    "        if debug_printing == True:\n",
    "          print(input_values.shape)\n",
    "\n",
    "        if input_values.dim() == 3:  # If the shape is [1, 1, audio_length]\n",
    "            input_values = input_values.squeeze(0)  # Squeeze to [1, audio_length]\n",
    "\n",
    "        if debug_printing == True:\n",
    "          print(input_values.shape)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.inference_mode():\n",
    "            logits = model0(input_values).logits\n",
    "\n",
    "        if debug_printing == True:\n",
    "         print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "        # Get the predicted token IDs (greedy decoding)\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        if debug_printing == True:\n",
    "          print(\"Predicted IDs shape:\", predicted_ids.shape)\n",
    "\n",
    "        # Convert predicted IDs to numpy array\n",
    "        predicted_ids = predicted_ids.cpu().numpy()\n",
    "\n",
    "        if debug_printing == True:\n",
    "          print(\"Predicted IDs (numpy):\", predicted_ids)\n",
    "\n",
    "        # Decode the predicted IDs\n",
    "        transcription = processor0.batch_decode(predicted_ids)[0]\n",
    "\n",
    "        if debug_printing == True:\n",
    "          print(\"Transcription:\", transcription)\n",
    "\n",
    "        return transcription\n",
    "\n",
    "\n",
    "\n",
    "def transcribe(input_file, output_folder, target_sr=target_sr, TIME_CHUNK=TIME_CHUNK):\n",
    "    # Load the audio\n",
    "    waveform, orig_sr = torchaudio.load(input_file)\n",
    "\n",
    "    # Check if resampling is needed\n",
    "    if orig_sr != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=orig_sr, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Determine the output file name and format (always WAV)\n",
    "    base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "\n",
    "    # Convert waveform to numpy array for easier processing\n",
    "    waveform_np = waveform.squeeze().numpy()\n",
    "\n",
    "\n",
    "################### RUN THE WHOLE AUDIO FILES ##########################\n",
    "    if testing_asr == True:\n",
    "            # Directly process the entire audio without chunking\n",
    "            #output_file = os.path.join(output_folder, f\"{base_name}_whole.wav\")\n",
    "            #torchaudio.save(output_file, waveform, sample_rate=target_sr)\n",
    "            tekst = process_transcribe(input_file)\n",
    "            # print(f\"Transcription for {base_name}: {tekst}\")\n",
    "            print(tekst)\n",
    "            #os.remove(output_file)  # Optionally delete the temporary WAV file\n",
    "    \n",
    "######### ELSE CHUNKS BASED ON TIME_CHUNK INCREMENTS ##################\n",
    "    else:\n",
    "        # Function to detect silence points\n",
    "        def find_silence_points(signal, threshold, min_silence_length, sr):\n",
    "            silence_points = []\n",
    "            min_silence_samples = int(min_silence_length * sr)\n",
    "            is_silence = np.abs(signal) < threshold\n",
    "            silence_length = 0\n",
    "            for i in range(len(is_silence)):\n",
    "                if is_silence[i]:\n",
    "                    silence_length += 1\n",
    "                    if silence_length >= min_silence_samples:\n",
    "                        silence_points.append(i)\n",
    "                else:\n",
    "                    silence_length = 0\n",
    "            return silence_points\n",
    "\n",
    "\n",
    "        # Find silence points in the audio\n",
    "        silence_points = find_silence_points(waveform_np, SILENCE_THRESHOLD, MIN_SILENCE_LENGTH, target_sr)\n",
    "    \n",
    "        if debug_printing == True:\n",
    "    \n",
    "            print(f\"Plotting point where silence ({len(silence_points)} points) has been detected in {input_file}\")\n",
    "            # Plot the waveform and silence points\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.plot(waveform_np, label='Waveform')\n",
    "            plt.scatter(silence_points, waveform_np[silence_points], color='red', marker='x', label='Silence Points')\n",
    "            plt.xlabel('Samples')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.title('Waveform with Silence Points')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "        # Split the audio at silence points\n",
    "        chunk_start = 0\n",
    "        for i, point in enumerate(silence_points):\n",
    "            chunk_end = point\n",
    "            if chunk_end - chunk_start >= TIME_CHUNK * target_sr:\n",
    "                chunk = waveform[:, chunk_start:chunk_end]\n",
    "                output_file = os.path.join(output_folder, f\"{base_name}_temp_chunk{i}.wav\")\n",
    "                torchaudio.save(output_file, chunk, sample_rate=target_sr)\n",
    "    \n",
    "                # Process the temporary WAV file\n",
    "                tekst = process_transcribe(output_file)\n",
    "                time = format_time(chunk_start / target_sr)\n",
    "                print(f\"[{time}] {tekst}\")\n",
    "    \n",
    "                # Optionally, you can delete the temporary WAV file after processing\n",
    "                os.remove(output_file)\n",
    "    \n",
    "                chunk_start = chunk_end\n",
    "                \n",
    "        def format_time(seconds):\n",
    "            minutes = int(seconds // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{minutes:02d}:{seconds:02d}\"\n",
    "    \n",
    "        # Process the remaining audio if any\n",
    "        if chunk_start < waveform.size(1):\n",
    "            chunk = waveform[:, chunk_start:]\n",
    "            output_file = os.path.join(output_folder, f\"{base_name}_temp_chunk{len(silence_points)}.wav\")\n",
    "            torchaudio.save(output_file, chunk, sample_rate=target_sr)\n",
    "            tekst = process_transcribe(output_file)\n",
    "            time = format_time(chunk_start / target_sr)\n",
    "            print(f\"[{time}] {tekst}\")\n",
    "            os.remove(output_file)\n",
    "\n",
    "\n",
    "print(f\"Transcription function defined and active: \\nSplitting audio in: {TIME_CHUNK}s segments (dynamically). \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:19.457130Z",
     "iopub.status.busy": "2024-06-16T17:02:19.457130Z",
     "iopub.status.idle": "2024-06-16T17:02:19.459777Z",
     "shell.execute_reply": "2024-06-16T17:02:19.459664Z",
     "shell.execute_reply.started": "2024-06-16T17:02:19.457130Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_printing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:19.746322Z",
     "iopub.status.busy": "2024-06-16T17:02:19.746322Z",
     "iopub.status.idle": "2024-06-16T17:02:19.759846Z",
     "shell.execute_reply": "2024-06-16T17:02:19.759846Z",
     "shell.execute_reply.started": "2024-06-16T17:02:19.746322Z"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1718360508968,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "15EPOU2EL7Xu",
    "outputId": "a676d1d2-e0d8-4746-a7d6-d1519087be8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is debug_printing on? True\n",
      "\n",
      "Transcription function defined and active: \n",
      "Splitting audio in: 20s segments (dynamically). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_CHUNK = 20\n",
    "target_sr=16000\n",
    "\n",
    "SILENCE_THRESHOLD = 0.01  # Threshold to detect silence\n",
    "MIN_SILENCE_LENGTH = 0.5  # Minimum length of silence to be considered a split point in seconds\n",
    "\n",
    "\n",
    "print(f\"Is debug_printing on? {debug_printing}\\n\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "\n",
    "# Assuming processor0lm and model0lm are initialized elsewhere\n",
    "# processor0lm = Wav2Vec2Processor.from_pretrained(...)\n",
    "# model0lm = Wav2Vec2ForSequenceClassification.from_pretrained(...)\n",
    "\n",
    "def process_transcribe_lm(input_file):\n",
    "\n",
    "    if debug_printing:\n",
    "        print(f\"input_file type {type(input_file)}\")\n",
    "        print(f\"input_file {input_file}\")\n",
    "    # Load audio and perform ASR using wav2vec2 with LM\n",
    "    speech, sample_rate = torchaudio.load(input_file)\n",
    "    \n",
    "    # Check if resampling is needed\n",
    "    target_sr = 16000  # Example target sampling rate\n",
    "    if sample_rate != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
    "        speech = resampler(speech)\n",
    "    \n",
    "    # Process the speech with the processor\n",
    "    input_values = processor0lm(speech, sampling_rate=target_sr, return_tensors=\"pt\").input_values.to(device)\n",
    "\n",
    "    if debug_printing:\n",
    "        print(\"Input values shape:\", input_values.shape)\n",
    "\n",
    "    # Ensure input_values has correct shape for model0lm\n",
    "    input_values = input_values.squeeze(0)  # Assuming batch_size=1\n",
    "\n",
    "    if debug_printing:\n",
    "        print(\"Adjusted input values shape:\", input_values.shape)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():  # Inference mode\n",
    "        logits = model0lm(input_values).logits\n",
    "\n",
    "    #logits = logits.squeeze(0)\n",
    "    # Ensure logits is a list of tensors\n",
    "    #logits_list = [logits]  # Wrap logits in a list\n",
    "\n",
    "\n",
    "    if debug_printing:\n",
    "        print(\"Logits shape after processing:\", logits.shape)\n",
    "        #print(\"Logits max value:\", np.amax(logits, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if debug_printing:\n",
    "        print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "    # Decode the predicted IDs\n",
    "    transcriptions = processor0lm.batch_decode(logits.numpy()).text\n",
    "\n",
    "    # Ensure transcription is returned as a string\n",
    "    transcription = transcriptions[0] if transcriptions else \"\"  # Assuming batch_size=1\n",
    "\n",
    "\n",
    "    if debug_printing:\n",
    "        print(\"Transcription:\", transcription)\n",
    "\n",
    "    return transcription\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_lm(input_file, output_folder, target_sr=target_sr, TIME_CHUNK=TIME_CHUNK):\n",
    "    # Load the audio\n",
    "    waveform, orig_sr = torchaudio.load(input_file)\n",
    "\n",
    "    # Check if resampling is needed\n",
    "    if orig_sr != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=orig_sr, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Determine the output file name and format (always WAV)\n",
    "    base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "\n",
    "    # Convert waveform to numpy array for easier processing\n",
    "    waveform_np = waveform.squeeze().numpy()\n",
    "\n",
    "    ################### RUN THE WHOLE AUDIO FILES ##########################\n",
    "    if testing_asr:\n",
    "        tekst = process_transcribe_lm(input_file)\n",
    "        print(f\"Transcription for {base_name}: {tekst}\")\n",
    "        # Optionally, save or process the transcription further\n",
    "        \n",
    "    \n",
    "        #return tekst\n",
    "\n",
    "\n",
    "\n",
    "# ################### RUN THE WHOLE AUDIO FILES ##########################\n",
    "#     if testing_asr == True:\n",
    "#             # Directly process the entire audio without chunking\n",
    "#             #output_file = os.path.join(output_folder, f\"{base_name}_whole.wav\")\n",
    "#             #torchaudio.save(output_file, waveform, sample_rate=target_sr)\n",
    "#             tekst = process_transcribe_lm(input_file)\n",
    "#             # print(f\"Transcription for {base_name}: {tekst}\")\n",
    "#             print(tekst)\n",
    "#             #os.remove(output_file)  # Optionally delete the temporary WAV file\n",
    "    \n",
    "######### ELSE CHUNKS BASED ON TIME_CHUNK INCREMENTS ##################\n",
    "    else:\n",
    "        # Function to detect silence points\n",
    "        def find_silence_points(signal, threshold, min_silence_length, sr):\n",
    "            silence_points = []\n",
    "            min_silence_samples = int(min_silence_length * sr)\n",
    "            is_silence = np.abs(signal) < threshold\n",
    "            silence_length = 0\n",
    "            for i in range(len(is_silence)):\n",
    "                if is_silence[i]:\n",
    "                    silence_length += 1\n",
    "                    if silence_length >= min_silence_samples:\n",
    "                        silence_points.append(i)\n",
    "                else:\n",
    "                    silence_length = 0\n",
    "            return silence_points\n",
    "\n",
    "\n",
    "        # Find silence points in the audio\n",
    "        silence_points = find_silence_points(waveform_np, SILENCE_THRESHOLD, MIN_SILENCE_LENGTH, target_sr)\n",
    "    \n",
    "        if debug_printing == True:\n",
    "    \n",
    "            print(f\"Plotting point where silence ({len(silence_points)} points) has been detected in {input_file}\")\n",
    "            # Plot the waveform and silence points\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.plot(waveform_np, label='Waveform')\n",
    "            plt.scatter(silence_points, waveform_np[silence_points], color='red', marker='x', label='Silence Points')\n",
    "            plt.xlabel('Samples')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.title('Waveform with Silence Points')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "        # Split the audio at silence points\n",
    "        chunk_start = 0\n",
    "        for i, point in enumerate(silence_points):\n",
    "            chunk_end = point\n",
    "            if chunk_end - chunk_start >= TIME_CHUNK * target_sr:\n",
    "                chunk = waveform[:, chunk_start:chunk_end]\n",
    "                output_file = os.path.join(output_folder, f\"{base_name}_temp_chunk{i}.wav\")\n",
    "                torchaudio.save(output_file, chunk, sample_rate=target_sr)\n",
    "    \n",
    "                # Process the temporary WAV file\n",
    "                tekst = process_transcribe_lm(output_file)\n",
    "                time = format_time(chunk_start / target_sr)\n",
    "                print(f\"[{time}] {tekst}\")\n",
    "    \n",
    "                # Optionally, you can delete the temporary WAV file after processing\n",
    "                os.remove(output_file)\n",
    "    \n",
    "                chunk_start = chunk_end\n",
    "                \n",
    "        def format_time(seconds):\n",
    "            minutes = int(seconds // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{minutes:02d}:{seconds:02d}\"\n",
    "    \n",
    "        # Process the remaining audio if any\n",
    "        if chunk_start < waveform.size(1):\n",
    "            chunk = waveform[:, chunk_start:]\n",
    "            output_file = os.path.join(output_folder, f\"{base_name}_temp_chunk{len(silence_points)}.wav\")\n",
    "            torchaudio.save(output_file, chunk, sample_rate=target_sr)\n",
    "            tekst = process_transcribe_lm(output_file)\n",
    "            time = format_time(chunk_start / target_sr)\n",
    "            print(f\"[{time}] {tekst}\")\n",
    "            os.remove(output_file)\n",
    "\n",
    "\n",
    "print(f\"Transcription function defined and active: \\nSplitting audio in: {TIME_CHUNK}s segments (dynamically). \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_ZwYCvBSBtG"
   },
   "source": [
    "## [6] Quick test to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:22.481929Z",
     "iopub.status.busy": "2024-06-16T17:02:22.481929Z",
     "iopub.status.idle": "2024-06-16T17:02:22.484798Z",
     "shell.execute_reply": "2024-06-16T17:02:22.484798Z",
     "shell.execute_reply.started": "2024-06-16T17:02:22.481929Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_pshr_wav2vec2_l = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\"\n",
    "path_to_pshr_wav2vec2_l_lm = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavic-hr-lm\"\n",
    "\n",
    "#test_audio_path_pc = r\"D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavic-hr-lm\\nela_film_review.ogg\" # WORKS WELL\n",
    "test_audio_path_pc = r\"D:\\ASR\\ParlaspeechHR\\ivan_snimka.opus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-16T17:02:22.746058Z",
     "iopub.status.busy": "2024-06-16T17:02:22.746058Z",
     "iopub.status.idle": "2024-06-16T17:02:29.350914Z",
     "shell.execute_reply": "2024-06-16T17:02:29.350300Z",
     "shell.execute_reply.started": "2024-06-16T17:02:22.746058Z"
    },
    "executionInfo": {
     "elapsed": 27946,
     "status": "ok",
     "timestamp": 1718360448610,
     "user": {
      "displayName": "Ivan Porupski",
      "userId": "03127310887960034948"
     },
     "user_tz": -120
    },
    "id": "qovFsXvCNTEc",
    "outputId": "d50a5b1a-a99b-43aa-d938-6b758934dbd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chunking. Per file basis. (testing_asr = True)\n",
      "\n",
      "torch.Size([1, 1, 490526])\n",
      "torch.Size([1, 490526])\n",
      "Logits shape: torch.Size([1, 1532, 50])\n",
      "Predicted IDs shape: torch.Size([1, 1532])\n",
      "Predicted IDs (numpy): [[ 1  1  1 ...  1  1 11]]\n",
      "Transcription: sada ti aljem glasovnu poruku i ne znam ta priam ali evo priam znai ovo tu mi je trebalo jedno 30 sati da doem do ovog trenutka priem normlno razgovjetno i nadam se da e transkripcija biti dobra naime ja to nisam izmislio nego su to zapravo r slovensa uzeli od facboka model i strenirali ga na govoru iz parlamenta specifino za hrvatski jeziki\n",
      "sada ti aljem glasovnu poruku i ne znam ta priam ali evo priam znai ovo tu mi je trebalo jedno 30 sati da doem do ovog trenutka priem normlno razgovjetno i nadam se da e transkripcija biti dobra naime ja to nisam izmislio nego su to zapravo r slovensa uzeli od facboka model i strenirali ga na govoru iz parlamenta specifino za hrvatski jeziki\n"
     ]
    }
   ],
   "source": [
    "if testing_asr == True:\n",
    "    print(f\"No chunking. Per file basis. (testing_asr = {testing_asr})\\n\")\n",
    "else:\n",
    "    print(f\"Chunking audio! Using silence points. (testing_asr = {testing_asr})\\n\")\n",
    "\n",
    "\n",
    "if google_colabbing == True:\n",
    "\n",
    "    test_audio_path = \"/content/drive/MyDrive/pytorch/wav2vec2-large-slavic-hr-lm/ivan_snimka.opus\"\n",
    "    test_audio_temp = \"/content/wav2vec2-large-slavic-parlaspeech-hr/temp\"\n",
    "    \n",
    "else:\n",
    "    if choose_lm_model == False:\n",
    "        # Obian model\n",
    "        test_audio_path = test_audio_path_pc\n",
    "        test_audio_temp = path_to_pshr_wav2vec2_l + r\"\\temp\"\n",
    "        transcribe(test_audio_path, test_audio_temp)\n",
    "        \n",
    "    else:\n",
    "        # LM model\n",
    "        test_audio_path = test_audio_path_pc\n",
    "        test_audio_temp = path_to_pshr_wav2vec2_l_lm + r\"\\temp\"\n",
    "        transcribe_lm(test_audio_path, test_audio_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:20.627641Z",
     "iopub.status.busy": "2024-06-16T17:03:20.627641Z",
     "iopub.status.idle": "2024-06-16T17:03:20.637907Z",
     "shell.execute_reply": "2024-06-16T17:03:20.637907Z",
     "shell.execute_reply.started": "2024-06-16T17:03:20.627641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 50\n"
     ]
    }
   ],
   "source": [
    "# Check the vocabulary size of the processor\n",
    "if choose_lm_model:\n",
    "    vocab_size = len(processor0lm.tokenizer.get_vocab())\n",
    "else:\n",
    "    vocab_size = len(processor0.tokenizer.get_vocab())\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zENOebskRMRG"
   },
   "source": [
    "# MODEL IS NOW OPERATIONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8dG337mSHjb"
   },
   "source": [
    "## [7] Prepare to run ling analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:27.130695Z",
     "iopub.status.busy": "2024-06-16T17:03:27.129698Z",
     "iopub.status.idle": "2024-06-16T17:03:28.859931Z",
     "shell.execute_reply": "2024-06-16T17:03:28.859737Z",
     "shell.execute_reply.started": "2024-06-16T17:03:27.129698Z"
    },
    "id": "uXKBhHqgNS7M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files in 'D:\\ParlaSpeech-HR.v1.0\\raw': 403925\n",
      "\n",
      "Number of entries in 'D:\\ParlaSpeech-HR.v1.0\\ParlaSpeech-HR.v1.0.jsonl': 403925\n",
      "\n",
      "CPU times: total: 469 ms\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "# Directory containing audio files\n",
    "path_to_pshr_raw_audio_data = r\"D:\\ParlaSpeech-HR.v1.0\\raw\"\n",
    "\n",
    "# List all files in the directory\n",
    "audio_files = os.listdir(path_to_pshr_raw_audio_data)\n",
    "\n",
    "# Count the number of audio files\n",
    "num_audio_files = len(audio_files)\n",
    "\n",
    "print(f\"Number of audio files in '{path_to_pshr_raw_audio_data}': {num_audio_files}\\n\")\n",
    "\n",
    "# JSONL file containing metadata\n",
    "path_to_pshr_raw_jsonl = r\"D:\\ParlaSpeech-HR.v1.0\\ParlaSpeech-HR.v1.0.jsonl\"\n",
    "\n",
    "# Counting lines in the JSONL file\n",
    "num_entries = 0\n",
    "with open(path_to_pshr_raw_jsonl, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        num_entries += 1\n",
    "\n",
    "print(f\"Number of entries in '{path_to_pshr_raw_jsonl}': {num_entries}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:31.728131Z",
     "iopub.status.busy": "2024-06-16T17:03:31.728131Z",
     "iopub.status.idle": "2024-06-16T17:03:31.735456Z",
     "shell.execute_reply": "2024-06-16T17:03:31.735456Z",
     "shell.execute_reply.started": "2024-06-16T17:03:31.728131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_transcriptions: {'seg.-k1z8behXXg_14758.42-14778.39.flac': ['km', 'i', 'distribuira', 'ih', 'na', 'nekih', 'dvije', 'tisue', 'esto', 'prikljuaka', 'zahvaa', 'jo', 'rubne', 'dijelove', 'nekih', 'drugih', 'lokalnih', 'jedinica', 'mogu', 're', 'da', 'ima', 'samo', 'osam', 'zaposlenih', 'ukupno', 'prihode', 'u', 'iznosu', 'od', 'etiriosam', 'milijuna', 'kuna', 'vrijednost', 'imovine', 'drutva', 'etrdeset', 'pet', 'milijuna', 'kuna', 'evo', 'dvije', 'tisue', 'etrnaest', 'do', 'dvije', 'tisue', 'osamnaest', 'je', 'realizirano', 'je', 'ukupno'], 'seg.1s4JHlcC_rM_9059.24-9078.75.flac': ['i', 'sudskih', 'postupaka', 'nedovreni', 'razliiti', 'postupci', 'koji', 'se', 'vode', 'zbog', 'utvrivanja', 'prava', 'vlasnitva', 'aktivne', 'plombe', 'kao', 'i', 'zavreeni', 'sudski', 'postupci', 'za', 'koje', 'u', 'zemljinim', 'knjigama', 'nisu', 'brisane', 'zabiljebe', 'sporova', 'cilj', 'je', 'nekretnine', 'dovesti', 'u', 'stanje', 'imovinsko', 'pravne', 'ali', 'i'], 'seg.NZR9CXgZNKA_5559.45-5578.77.flac': ['meutim', 's', 'druge', 'strane', 'moramo', 'znati', 'da', 'vrlo', 'esto', 'postoje', 'snani', 'javni', 'opi', 'interesi', 'za', 'izgradnju', 'infrastrukturnih', 'objekata', 'za', 'izgradnjom', 'kola', 'bolnica', 'cesta', 'eljeznike', 'infrastrukture', 'i', 'da', 'ti', 'objekti'], 'seg.a9Jz6KAkBFs_2680.84-2700.52.flac': ['se', 'pozivati', 'na', 'to', 'kao', 'da', 'je', 'on', 'jedini', 'bogom', 'dan', 'da', 'spasi', 'ovu', 'hrvatsku', 'a', 'svi', 'ostali', 'nita', 'ne', 'razumiju', 'pa', 'se', 'tako', 'razbacaju', 'i', 'sa', 'rijeima', 'i', 'sa', 'time', 'da', 'ne', 'respektira', 'ta', 'graani', 'erha', 'misle', 'o', 'ovom', 'konkretnom', 'sluaju', 'ne', 'respektira', 'o', 'tome', 'to', 'misle', 'da', 'on', 'krivo', 'vodi', 'hrvatsku'], 'seg.qNpeHxO0WzA_1967.6-1986.11.flac': ['primjeni', 'eljeznikih', 'paketa', 'kojima', 'se', 'postupno', 'i', 'nezaustavljivo', 'stvara', 'jedinstveni', 'europski', 'eljezniki', 'prostor', 'provedba', 'ovog', 'zakona', 'nema', 'financijski', 'utjecaj', 'na', 'dravni', 'proraun', 'hvala', 'lijepo', 'zahvaljujem', 'ministru', 'imamo', 'sedam', 'replika', 'prvi', 'je', 'kolega', 'kirin', 'izvolite']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Paths to your data\n",
    "path_to_pshr_raw_audio_data = r\"D:\\ParlaSpeech-HR.v1.0\\raw\"\n",
    "path_to_pshr_raw_jsonl = r\"D:\\ParlaSpeech-HR.v1.0\\ParlaSpeech-HR.v1.0.jsonl\"\n",
    "\n",
    "# Limit number of transcriptions to print\n",
    "limit = 5\n",
    "count = 0\n",
    "\n",
    "# Read JSONL file\n",
    "audio_transcriptions = {}\n",
    "with open(path_to_pshr_raw_jsonl, 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        if count >= limit:\n",
    "            break\n",
    "        \n",
    "        data = json.loads(line.strip())\n",
    "        audio_filename = os.path.basename(data['path'])\n",
    "        audio_transcriptions[audio_filename] = data['norm_words']  # Use 'norm_words' or other transcription field\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "audio_transcriptions = dict(sorted(audio_transcriptions.items()))\n",
    "\n",
    "print(f\"audio_transcriptions: {audio_transcriptions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generiranje audio_transcriptions dict(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T16:37:23.531601Z",
     "iopub.status.busy": "2024-06-16T16:37:23.531601Z",
     "iopub.status.idle": "2024-06-16T16:37:36.223962Z",
     "shell.execute_reply": "2024-06-16T16:37:36.223895Z",
     "shell.execute_reply.started": "2024-06-16T16:37:23.531601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL AUDIO_TRANSCRIPTIONS HERE\n",
      "CPU times: total: 12.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"FULL AUDIO_TRANSCRIPTIONS HERE\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Paths to your data\n",
    "path_to_pshr_raw_audio_data = r\"D:\\ParlaSpeech-HR.v1.0\\raw\"\n",
    "path_to_pshr_raw_jsonl = r\"D:\\ParlaSpeech-HR.v1.0\\ParlaSpeech-HR.v1.0.jsonl\"\n",
    "\n",
    "# Read JSONL file\n",
    "audio_transcriptions = {}\n",
    "with open(path_to_pshr_raw_jsonl, 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        data = json.loads(line.strip())\n",
    "        audio_filename = os.path.basename(data['path'])\n",
    "        audio_transcriptions[audio_filename] = data['norm_words']  # Use 'norm_words' or other transcription field\n",
    "\n",
    "audio_transcriptions = dict(sorted(audio_transcriptions.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T16:37:36.225892Z",
     "iopub.status.busy": "2024-06-16T16:37:36.224896Z",
     "iopub.status.idle": "2024-06-16T16:37:36.396207Z",
     "shell.execute_reply": "2024-06-16T16:37:36.396207Z",
     "shell.execute_reply.started": "2024-06-16T16:37:36.225892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first 3 audio names w/ transcription:\n",
      "\n",
      "debug_printing: True\n",
      "First 10 Files:\n",
      "['seg.-EO06cT21uY_10038.21-10054.64.flac', 'seg.-EO06cT21uY_10111.7-10131.55.flac', 'seg.-EO06cT21uY_10131.55-10147.16.flac', 'seg.-EO06cT21uY_10148.69-10167.91.flac', 'seg.-EO06cT21uY_10167.91-10186.62.flac', 'seg.-EO06cT21uY_10187.44-10207.4.flac', 'seg.-EO06cT21uY_10207.4-10227.1.flac', 'seg.-EO06cT21uY_10227.1-10246.72.flac', 'seg.-EO06cT21uY_10246.72-10265.92.flac', 'seg.-EO06cT21uY_10266.15-10285.99.flac']\n",
      "\n",
      "Audio Transcriptions:\n",
      "seg.-EO06cT21uY_10038.21-10054.64.flac: ['lijepo', 'kolegice', 'i', 'kolege', 'nemojte', 'se', 'vi', 'varda', 'hihotat', 'prije', 'etirig', 'ste', 'izdali', 'birae', 'sad', 'jedva', 'ekam', 'da', 'vidim', 'kako', 'e', 'vas', 'nagradit', 'jedva', 'ekam', 'hvala', 'lijepo', 'kolegice', 'i', 'kolega', 'kolege', 'zastupnici', 'g', 'potpredsjednie']\n",
      "seg.-EO06cT21uY_10111.7-10131.55.flac: ['hadeze', 'eli', 'pokuati', 'dati', 'obeanje', 'za', 'est', 'mjeseci', 'da', 'e', 'neki', 'graani', 'dobiti', 'osam', 'stotina', 'kuna', 'i', 'jedina', 'svrha', 'ovog', 'zakona', 'su', 'je', 'kampanja', 'odnosno', 'izbori', 'i', 'predizborna', 'kampanja', 'jer', 'kako', 'drugaije', 'objasniti', 'da', 'niste', 'dali', 'kada']\n",
      "seg.-EO06cT21uY_10131.55-10147.16.flac: ['ste', 'imali', 'rast', 'tri', 'posto', 'a', 'sada', 'predlae', 'kao', 'fol', 'g', 'aladrovi', 'i', 'plenkovi', 'se', 'brinu', 'za', 'nae', 'starije', 'sugraane', 'i', 'evo', 'kad', 'emo', 'imati', 'pad', 'od', 'deset', 'posto', 'izdvojili', 'su', 'osamsto', 'kuna']\n",
      "\n",
      "Correlating audio files with transcriptions:\n",
      "\n",
      "Audio File:\n",
      "seg.-EO06cT21uY_10038.21-10054.64.flac\n",
      "\n",
      "Transcription:\n",
      "lijepo kolegice i kolege nemojte se vi varda hihotat prije etirig ste izdali birae sad jedva ekam da vidim kako e vas nagradit jedva ekam hvala lijepo kolegice i kolega kolege zastupnici g potpredsjednie\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Audio File:\n",
      "seg.-EO06cT21uY_10111.7-10131.55.flac\n",
      "\n",
      "Transcription:\n",
      "hadeze eli pokuati dati obeanje za est mjeseci da e neki graani dobiti osam stotina kuna i jedina svrha ovog zakona su je kampanja odnosno izbori i predizborna kampanja jer kako drugaije objasniti da niste dali kada\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Audio File:\n",
      "seg.-EO06cT21uY_10131.55-10147.16.flac\n",
      "\n",
      "Transcription:\n",
      "ste imali rast tri posto a sada predlae kao fol g aladrovi i plenkovi se brinu za nae starije sugraane i evo kad emo imati pad od deset posto izdvojili su osamsto kuna\n",
      "------------------------------\n",
      "\n",
      "\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Print limited number of audio_transcriptions\n",
    "limit = 3\n",
    "count = 0\n",
    "\n",
    "print(f\"Displaying first {limit} audio names w/ transcription:\\n\")\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = os.listdir(path_to_pshr_raw_audio_data)\n",
    "\n",
    "# Sort the files alphabetically or by any other criteria, if needed\n",
    "all_files.sort()\n",
    "\n",
    "# Select the first 10 files\n",
    "first_10_files = all_files[:10]\n",
    "\n",
    "print(f\"debug_printing: {debug_printing}\")\n",
    "\n",
    "if debug_printing == True:\n",
    "    # Debug prints\n",
    "    print(\"First 10 Files:\")\n",
    "    print(first_10_files)\n",
    "    print(\"\\nAudio Transcriptions:\")\n",
    "\n",
    "for filename, transcription in audio_transcriptions.items():\n",
    "    if count >= limit:\n",
    "        break\n",
    "    if debug_printing == True:\n",
    "        print(f\"{filename}: {transcription}\")\n",
    "    count += 1\n",
    "\n",
    "# Step 3: Correlate audio files with transcriptions (limiting to 'limit' iterations)\n",
    "print(\"\\nCorrelating audio files with transcriptions:\\n\")\n",
    "for i, audio_file in enumerate(first_10_files[:limit]):\n",
    "    if audio_file in audio_transcriptions:\n",
    "        transcription = ' '.join(audio_transcriptions[audio_file])\n",
    "        print(f\"Audio File:\\n{audio_file}\\n\\nTranscription:\\n{transcription}\")\n",
    "    else:\n",
    "        print(f\"No transcription found for {audio_file}\")\n",
    "    \n",
    "    # Add a separator between iterations for clarity, except after the last item\n",
    "    if i < (limit):\n",
    "        print(\"-\" * 30)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING TRANSCRIPTIONS now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the first 5 .flac files\n",
    "for i, audio_file in enumerate(all_files[:5]):\n",
    "    if audio_file.endswith('.flac'):\n",
    "        flac_audio_path = os.path.join(path_to_pshr_raw_audio_data, audio_file)\n",
    "        transcribe(flac_audio_path, test_audio_temp)\n",
    "    else:\n",
    "        print(f\"Skipping non-FLAC file: {audio_file}\")\n",
    "\n",
    "    # Add a separator between iterations for clarity\n",
    "    if i < 4:  # Adjust the limit based on the number of files you want to process\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:42.339096Z",
     "iopub.status.busy": "2024-06-16T17:03:42.339096Z",
     "iopub.status.idle": "2024-06-16T17:03:42.919099Z",
     "shell.execute_reply": "2024-06-16T17:03:42.919099Z",
     "shell.execute_reply.started": "2024-06-16T17:03:42.339096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions online.\n"
     ]
    }
   ],
   "source": [
    "## NEW\n",
    "\n",
    "import os\n",
    "from jiwer import wer\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "similarity_threshold = 50  # Example threshold, can be adjusted based on requirements\n",
    "max_search_distance = 3  # Maximum number of tokens to search ahead for a match\n",
    "\n",
    "# Function to tokenize text by removing dots and commas, then splitting into tokens\n",
    "def tokenize_text(text):\n",
    "    # Remove dots and commas\n",
    "    if debug_printing == True:\n",
    "        print(f\"Type of text: {type(text)}\")\n",
    "    \n",
    "    text = text.replace('.', '').replace(',', '')\n",
    "    # Convert to lowercase and split into tokens\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Function to normalize numbers within tokens\n",
    "def normalize_numbers(tokens, norm_nums):\n",
    "    def decompose_number(num):\n",
    "        components = []\n",
    "        if num >= 1000:\n",
    "            thousands = num // 1000 * 1000\n",
    "            components.append(thousands)\n",
    "            num %= 1000\n",
    "        if num >= 100:\n",
    "            hundreds = num // 100 * 100\n",
    "            components.append(hundreds)\n",
    "            num %= 100\n",
    "        if num >= 20:\n",
    "            tens = num // 10 * 10\n",
    "            components.append(tens)\n",
    "            num %= 10\n",
    "        if num > 0:\n",
    "            components.append(num)\n",
    "        return components\n",
    "\n",
    "    normalized_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "            num = int(token)\n",
    "            components = decompose_number(num)\n",
    "            for component in components:\n",
    "                if component in norm_nums:\n",
    "                    normalized_tokens.append(norm_nums[component])\n",
    "        elif token.lower() in norm_nums:\n",
    "            normalized_tokens.append(norm_nums[token.lower()])\n",
    "        else:\n",
    "            normalized_tokens.append(token)\n",
    "    \n",
    "    # Flatten the list in case there are combined tokens like \"dvije tisue\"\n",
    "    flattened_tokens = []\n",
    "    for token in normalized_tokens:\n",
    "        if ' ' in token:\n",
    "            flattened_tokens.extend(token.split())\n",
    "        else:\n",
    "            flattened_tokens.append(token)\n",
    "    \n",
    "    return flattened_tokens\n",
    "    \n",
    "\n",
    "\n",
    "# OLD BUT GOOD Function to normalize numbers based on the predefined mapping\n",
    "# def normalize_numbers(tokens, norm_nums):\n",
    "#     normalized_tokens = []\n",
    "#     for token in tokens:\n",
    "#         if token.lower() in norm_nums:\n",
    "#             normalized_tokens.append(norm_nums[token.lower()])\n",
    "#         elif token.isdigit() and int(token) in norm_nums:\n",
    "#             normalized_tokens.append(norm_nums[int(token)])\n",
    "#         else:\n",
    "#             normalized_tokens.append(token)\n",
    "#     return normalized_tokens\n",
    "\n",
    "# Function to align ASR tokens with original tokens based on character similarity\n",
    "def align_tokens(original_tokens, asr_tokens, similarity_threshold=similarity_threshold):\n",
    "    aligned_asr_tokens = []\n",
    "    asr_index = 0\n",
    "    \n",
    "    for original_token in original_tokens:\n",
    "        found_match = False\n",
    "        search_end = min(asr_index + max_search_distance, len(asr_tokens))\n",
    "        for i in range(asr_index, search_end):\n",
    "            asr_token = asr_tokens[i]\n",
    "            similarity = fuzz.ratio(original_token, asr_token)\n",
    "            \n",
    "            if debug_printing == True:\n",
    "                print(f\"Comparing original token '{original_token}' with ASR token '{asr_token}': Similarity = {similarity}\")\n",
    "                \n",
    "            if similarity >= similarity_threshold:\n",
    "                # Found a match, so align both original and ASR tokens\n",
    "                aligned_asr_tokens.append(asr_token)\n",
    "                asr_index = i + 1  # Move the ASR index forward\n",
    "                found_match = True\n",
    "                \n",
    "                if debug_printing == True:\n",
    "                    print(f\"Match found for '{original_token}' with '{asr_token}'\")\n",
    "                    \n",
    "                break\n",
    "        \n",
    "        if not found_match:\n",
    "            # No match found within the search distance, handle as needed (optional)\n",
    "            # For simplicity, you can decide to skip or handle cases where no match is found\n",
    "            if debug_printing == True:\n",
    "                print(f\"No match found for '{original_token}', handling case...\")\n",
    "    \n",
    "    if debug_printing == True:\n",
    "        print(f\"Aligned ASR tokens: {aligned_asr_tokens}\\n\")\n",
    "        \n",
    "    return aligned_asr_tokens\n",
    "\n",
    "print(f\"Functions online.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiranje znamenki (robustnost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:43.794230Z",
     "iopub.status.busy": "2024-06-16T17:03:43.793233Z",
     "iopub.status.idle": "2024-06-16T17:03:43.799776Z",
     "shell.execute_reply": "2024-06-16T17:03:43.799724Z",
     "shell.execute_reply.started": "2024-06-16T17:03:43.794230Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the mappings for numbers in Croatian\n",
    "norm_nums = {\n",
    "    1: 'jedan',\n",
    "    2: 'dva',\n",
    "    3: 'tri',\n",
    "    4: 'etiri',\n",
    "    5: 'pet',\n",
    "    6: 'est',\n",
    "    7: 'sedam',\n",
    "    8: 'osam',\n",
    "    9: 'devet',\n",
    "    10: 'deset',\n",
    "    11: 'jedanaest',\n",
    "    12: 'dvanaest',\n",
    "    13: 'trinaest',\n",
    "    14: 'etrnaest',\n",
    "    15: 'petnaest',\n",
    "    16: 'esnaest',\n",
    "    17: 'sedamnaest',\n",
    "    18: 'osamnaest',\n",
    "    19: 'devetnaest',\n",
    "    20: 'dvadeset',\n",
    "    30: 'trideset',\n",
    "    40: 'etrdeset',\n",
    "    50: 'pedeset',\n",
    "    60: 'ezdeset',\n",
    "    70: 'sedamdeset',\n",
    "    80: 'osamdeset',\n",
    "    90: 'devedeset',\n",
    "    100: 'sto',\n",
    "    200: 'dvjesto',\n",
    "    300: 'tristo',\n",
    "    400: 'etiristo',\n",
    "    500: 'petsto',\n",
    "    600: 'esto',\n",
    "    700: 'sedamsto',\n",
    "    800: 'osamsto',\n",
    "    900: 'devetsto',\n",
    "    1000: 'tisua',\n",
    "    2000: 'dvije tisue',  # Two thousand\n",
    "    3000: 'tri tisue',    # Three thousand\n",
    "    4000: 'etiri tisue', # Four thousand\n",
    "    5000: 'pet tisua',    # Five thousand\n",
    "    6000: 'est tisua',   # Six thousand\n",
    "    7000: 'sedam tisua',  # Seven thousand\n",
    "    8000: 'osam tisua',   # Eight thousand\n",
    "    9000: 'devet tisua',  # Nine thousand\n",
    "}\n",
    "\n",
    "# Create the reverse mapping for Croatian numbers\n",
    "norm_nums_reverse = {value: key for key, value in norm_nums.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:03:44.601805Z",
     "iopub.status.busy": "2024-06-16T17:03:44.601805Z",
     "iopub.status.idle": "2024-06-16T17:03:44.605819Z",
     "shell.execute_reply": "2024-06-16T17:03:44.605819Z",
     "shell.execute_reply.started": "2024-06-16T17:03:44.601805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text: <class 'str'>\n",
      "Tokens: ['ovo', 'je', '2012', 'godina', 'zar', 'ne']\n",
      "Normalized Tokens: ['ovo', 'je', 'dvije', 'tisue', 'dvanaest', 'godina', 'zar', 'ne']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tekst = \"Ovo je 2012. godina, zar ne\"\n",
    "\n",
    "asr_tokens = tokenize_text(tekst)\n",
    "print(\"Tokens:\", asr_tokens)\n",
    "\n",
    "normalized_tokens = normalize_numbers(asr_tokens, norm_nums)\n",
    "normalized_tokens = normalized_tokens\n",
    "print(\"Normalized Tokens:\", normalized_tokens)\n",
    "\n",
    "# Expected output\n",
    "# Tokens: ['ovo', 'je', '2012', 'godina', 'zar', 'ne']\n",
    "# Normalized Tokens: ['ovo', 'je', 'dvije', 'tisue', 'dvanaest', 'godina', 'zar', 'ne']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run WER matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:04:18.118027Z",
     "iopub.status.busy": "2024-06-16T17:04:18.118027Z",
     "iopub.status.idle": "2024-06-16T17:04:18.139839Z",
     "shell.execute_reply": "2024-06-16T17:04:18.139839Z",
     "shell.execute_reply.started": "2024-06-16T17:04:18.118027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WER_results for OLD DEFAULT VERSION...\n",
      "Loaded WER_results from: D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\\WER_results_v3.3.json\n"
     ]
    }
   ],
   "source": [
    "debug_printing = False\n",
    "WER_results = []\n",
    "WER_results_LM = []\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "if choose_lm_model == False:\n",
    "    dict_file_path = path_to_pshr_wav2vec2_l\n",
    "    wer_plot_save_path = dict_file_path\n",
    "    dict_main_name = f\"WER_results_{work_version}.json\"\n",
    "    old_default_version = \"v3.3\"\n",
    "    old_dict_main_name = f\"WER_results_{old_default_version}.json\"\n",
    "    \n",
    "else: \n",
    "    dict_file_path = path_to_pshr_wav2vec2_l_lm\n",
    "    wer_plot_save_path = dict_file_path\n",
    "    dict_main_name = f\"WER_results_LM_{work_version}.json\"\n",
    "    old_default_version_lm = \"v3.3\"\n",
    "    old_dict_main_name = f\"WER_results_LM_{old_default_version_lm}.json\"\n",
    "\n",
    "\n",
    "# dict_main_name = f\"WER_results_{work_version}.json\"\n",
    "# old_default_version = \"v3.2\"\n",
    "# old_dict_main_name = f\"WER_results_{old_default_version}.json\"\n",
    "\n",
    "dict_file_path_full = os.path.join(dict_file_path, dict_main_name)\n",
    "old_dict_file_path_full = os.path.join(dict_file_path, old_dict_main_name)\n",
    "\n",
    "# Check if the file for the current work version exists\n",
    "if os.path.exists(dict_file_path_full):\n",
    "    print(f\"Loading WER_results for CURRENT VERSION...\")\n",
    "    # Load existing data from JSON file for current version\n",
    "    with open(dict_file_path_full, \"r\") as f:\n",
    "        WER_results = json.load(f)\n",
    "    print(f\"Loaded WER_results from: {dict_file_path_full}\")\n",
    "    wer_plot_from_version = dict_main_name\n",
    "    \n",
    "\n",
    "# Check if the file for the old default version exists\n",
    "elif os.path.exists(old_dict_file_path_full):\n",
    "    print(f\"Loading WER_results for OLD DEFAULT VERSION...\")\n",
    "    # Load existing data from JSON file for old default version\n",
    "    with open(old_dict_file_path_full, \"r\") as f:\n",
    "        WER_results = json.load(f)\n",
    "    print(f\"Loaded WER_results from: {old_dict_file_path_full}\")\n",
    "    wer_plot_from_version = old_dict_main_name\n",
    "\n",
    "# Neither file exists, initialize WER_results as an empty list\n",
    "else:\n",
    "    WER_results = []\n",
    "    WER_results_LM = []\n",
    "    print(f\"No WER_results or _LM Dict found for either current or old default version.\\nMaking a new empty one...\")\n",
    "\n",
    "\n",
    "    \n",
    "# dict_main_name = f\"WER_results_{work_version}.json\"\n",
    "\n",
    "# dict_file_path_full = os.path.join(dict_file_path, dict_main_name)\n",
    "\n",
    "\n",
    "# # Check if the file exists\n",
    "# if os.path.exists(dict_file_path_full):\n",
    "    \n",
    "#     print(f\"Loading WER_results...\")\n",
    "#     # Load existing data from JSON file\n",
    "#     with open(dict_file_path_full, \"r\") as f:\n",
    "#         WER_results = json.load(f)\n",
    "#     print(f\"Loaded WER_results from: {dict_file_path_full}\")\n",
    "    \n",
    "# else:\n",
    "#     # Initialize WER_results as an empty list\n",
    "#     WER_results = []\n",
    "#     print(f\"No WER_results Dict found.\\nMaking a new empty one...\")\n",
    "\n",
    "\n",
    "# with open(dict_file_path_full, \"w\") as f:\n",
    "#     json.dump(WER_results, f, indent=4)\n",
    "\n",
    "# print(f\"Saving dict to: {dict_file_path}\\  \\n\\nFilename: {dict_main_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:04:31.499112Z",
     "iopub.status.busy": "2024-06-16T17:04:31.499112Z",
     "iopub.status.idle": "2024-06-16T17:04:38.643746Z",
     "shell.execute_reply": "2024-06-16T17:04:38.643319Z",
     "shell.execute_reply.started": "2024-06-16T17:04:31.499112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 1: 100%|| 2/2 [00:07<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved dict to: D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\\  \n",
      "\n",
      "Filename: WER_results_v3.4.json\n",
      "\n",
      "Number of runs: 1\n",
      "Total number of audio processed: 2\n",
      "\n",
      "Number of WER_results: 1988\n",
      "\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 7.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# treba 4s po jednom audio fileu\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Variables to accumulate metrics\n",
    "num_runs = 1  # Number of runs to average over (SAVES DICT EACH RUN)\n",
    "max_files_to_process = 2  # Number of files to process per run (20 files = 1 min)\n",
    "\n",
    "transcription_list = list(audio_transcriptions.items())\n",
    "\n",
    "# Iterate over each run\n",
    "for run in range(num_runs):\n",
    "    total_asr_deletions = 0\n",
    "    total_asr_additions = 0\n",
    "    total_asr_substitutions = 0  # Total substitutions across all files\n",
    "    total_tokens = 0\n",
    "    total_error_rate = 0.0\n",
    "    n = 0  # Number of files processed\n",
    "    \n",
    "    # Shuffle the transcription list for each run if needed\n",
    "    if shuffle_transcript == True:\n",
    "        random.shuffle(transcription_list)\n",
    "    \n",
    "    # Use tqdm to show progress for processing each file in the run\n",
    "    with tqdm(total=max_files_to_process, desc=f\"Run {run+1}\") as pbar:\n",
    "        # Process up to max_files_to_process files for this run\n",
    "        run_results = []\n",
    "        for file_idx in range(min(max_files_to_process, len(transcription_list))):  # Ensure we don't exceed the list length\n",
    "            input_file, transcription = transcription_list[file_idx]\n",
    "\n",
    "\n",
    "\n",
    "            if choose_lm_model == False:\n",
    "                # Process transcription from ASR system\n",
    "                tekst = process_transcribe(os.path.join(path_to_pshr_raw_audio_data, input_file))\n",
    "\n",
    "            else:\n",
    "                tekst = process_transcribe_lm(os.path.join(path_to_pshr_raw_audio_data, input_file))\n",
    "\n",
    "            \n",
    "            # Get original transcription from dictionary\n",
    "            original_transcription = ' '.join(audio_transcriptions[input_file])\n",
    "            \n",
    "            # Tokenize both transcriptions\n",
    "            original_tokens = tokenize_text(original_transcription)\n",
    "            asr_tokens = tokenize_text(tekst)\n",
    "        \n",
    "            # Normalize numbers in ASR tokens\n",
    "            normalized_asr_tokens = normalize_numbers(asr_tokens, norm_nums)\n",
    "        \n",
    "            # Align ASR tokens with original tokens based on character similarity\n",
    "            aligned_asr_tokens = align_tokens(original_tokens, normalized_asr_tokens, similarity_threshold=similarity_threshold)\n",
    "        \n",
    "            # Calculate error metrics\n",
    "            asr_deletion = len(original_tokens) - len(aligned_asr_tokens)\n",
    "            asr_addition = len(normalized_asr_tokens) - len(aligned_asr_tokens)\n",
    "            \n",
    "            # Calculate substitutions between original and aligned ASR tokens\n",
    "            substitutions = 0\n",
    "            for orig_token, asr_token in zip(original_tokens, aligned_asr_tokens):\n",
    "                if orig_token != asr_token:\n",
    "                    substitutions += 1\n",
    "            \n",
    "            total_asr_substitutions += substitutions\n",
    "            total_tokens = len(original_tokens)\n",
    "            error_rate = (asr_deletion + asr_addition + substitutions) / total_tokens\n",
    "        \n",
    "            # Accumulate metrics\n",
    "            total_asr_deletions += asr_deletion\n",
    "            total_asr_additions += asr_addition\n",
    "            total_error_rate += error_rate\n",
    "            n += 1\n",
    "\n",
    "            # Store individual file results for this run including substitutions\n",
    "            file_result = {\n",
    "                \"input_file\": input_file,\n",
    "                \"tokens\": total_tokens,\n",
    "                \"asr_deletions\": asr_deletion,\n",
    "                \"asr_additions\": asr_addition,\n",
    "                \"asr_substitutions\": substitutions,\n",
    "                \"error_rate\": error_rate\n",
    "            }\n",
    "\n",
    "            WER_results.append(file_result)  # Append to WER_results\n",
    "        \n",
    "            # Update tqdm progress bar\n",
    "            pbar.update(1)\n",
    "    \n",
    "            # Print or use the error metric for each file as needed\n",
    "            if debug_printing == True:\n",
    "                print(f\"Transcription {input_file}: {tekst}\")\n",
    "                print(f\"original_tokens: \\n{original_tokens}\\n\")\n",
    "                print(f\"asr_tokens: \\n{asr_tokens}\\n\")\n",
    "                print(f\"normalized_asr_tokens: \\n{normalized_asr_tokens}\\n\")\n",
    "                print(f\"aligned_asr_tokens: \\n{aligned_asr_tokens}\\n\")\n",
    "                print(f\"ASR Deletions: {asr_deletion}\")\n",
    "                print(f\"ASR Additions: {asr_addition}\")\n",
    "                print(f\"ASR Substitutions: {substitutions}\")\n",
    "                print(f\"Total Tokens: {len(original_tokens)}\")\n",
    "                print(f\"Error Rate (WER): {error_rate}\\n\")\n",
    "\n",
    "      \n",
    "        # Calculate average error metrics for this run\n",
    "        average_asr_deletions = total_asr_deletions / n\n",
    "        average_asr_additions = total_asr_additions / n\n",
    "        average_asr_substitutions = total_asr_substitutions / n\n",
    "        average_error_rate = total_error_rate / n\n",
    "     \n",
    "        # Store average results for this run\n",
    "        run_result = {\n",
    "            \"average_asr_deletions\": average_asr_deletions,\n",
    "            \"average_asr_additions\": average_asr_additions,\n",
    "            \"average_asr_substitutions\": average_asr_substitutions,\n",
    "            \"average_error_rate\": average_error_rate\n",
    "        }\n",
    "    \n",
    "        # Append run_results to results list for this run\n",
    "        WER_results.append(run_result)\n",
    "\n",
    "        with open(dict_file_path_full, \"w\") as f:\n",
    "            json.dump(WER_results, f, indent=4)\n",
    "            \n",
    "        if debug_printing == True:\n",
    "            print(f\"Saving dict to: {dict_file_path}\\  \\n\\nFilename: {dict_main_name}\\n\")\n",
    "\n",
    "\n",
    "if debug_printing == True:\n",
    "    # Print or process results as needed\n",
    "    for run_idx, run_result in enumerate(WER_results):\n",
    "        print(f\"Run {run_idx + 1} Results:\")\n",
    "        for file_result in run_result:\n",
    "            print(f\"Input File: {file_result['input_file']}\")\n",
    "            print(f\"ASR Deletions: {file_result['asr_deletions']}\")\n",
    "            print(f\"ASR Additions: {file_result['asr_additions']}\")\n",
    "            print(f\"Error Rate (WER): {file_result['error_rate']}\")\n",
    "        print()\n",
    "\n",
    "print(f\"\\nSaved dict to: {dict_file_path}\\  \\n\\nFilename: {dict_main_name}\\n\")\n",
    "\n",
    "# Print number of runs\n",
    "print(f\"Number of runs: {num_runs}\")\n",
    "print(f\"Total number of audio processed: {max_files_to_process*num_runs}\\n\")\n",
    "print(f\"Number of WER_results: {len(WER_results)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results WER_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:04:47.000934Z",
     "iopub.status.busy": "2024-06-16T17:04:47.000934Z",
     "iopub.status.idle": "2024-06-16T17:04:47.009873Z",
     "shell.execute_reply": "2024-06-16T17:04:47.009873Z",
     "shell.execute_reply.started": "2024-06-16T17:04:47.000934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Total ASR Deletions: 2544\n",
      "Overall Total ASR Additions: 1835\n",
      "Overall Total ASR Substitutions: 21424\n",
      "Overall Total Original Tokens: 68313\n",
      "\n",
      "Overall Word Error Rate (WER): 0.3777\n",
      "\n",
      "Number of individual files processed: 1988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall totals across all runs\n",
    "overall_total_asr_deletions = sum(result.get(\"asr_deletions\", 0) for result in WER_results if isinstance(result, dict))\n",
    "overall_total_asr_additions = sum(result.get(\"asr_additions\", 0) for result in WER_results if isinstance(result, dict))\n",
    "overall_total_asr_substitutions = sum(result.get(\"asr_substitutions\", 0) for result in WER_results if isinstance(result, dict))\n",
    "overall_total_tokens = sum(result.get(\"tokens\", 0) for result in WER_results if isinstance(result, dict))\n",
    "\n",
    "# Calculate overall error rate\n",
    "total_files_with_error_rate = sum(1 for result in WER_results if isinstance(result, dict) and \"error_rate\" in result)\n",
    "overall_total_error_rate = sum(result[\"error_rate\"] for result in WER_results if isinstance(result, dict) and \"error_rate\" in result) / total_files_with_error_rate if total_files_with_error_rate > 0 else 0\n",
    "\n",
    "# Print overall totals including substitutions\n",
    "print(f\"Overall Total ASR Deletions: {overall_total_asr_deletions}\")\n",
    "print(f\"Overall Total ASR Additions: {overall_total_asr_additions}\")\n",
    "print(f\"Overall Total ASR Substitutions: {overall_total_asr_substitutions}\")\n",
    "print(f\"Overall Total Original Tokens: {overall_total_tokens}\\n\")\n",
    "\n",
    "# Calculate WER\n",
    "wer = (overall_total_asr_deletions + overall_total_asr_additions + overall_total_asr_substitutions) / overall_total_tokens\n",
    "\n",
    "# Print WER\n",
    "print(f\"Overall Word Error Rate (WER): {wer:.4f}\\n\")\n",
    "\n",
    "# Print overall average error metrics\n",
    "# print(f\"Overall Average ASR Deletions: {overall_total_asr_deletions / num_files_processed:.4f}\")\n",
    "# print(f\"Overall Average ASR Additions: {overall_total_asr_additions / num_files_processed:.4f}\")\n",
    "# print(f\"Overall Average ASR Substitutions: {overall_total_asr_substitutions / num_files_processed:.4f}\")\n",
    "# print(f\"Overall Average Error Rate (WER): {overall_total_error_rate:.4f}\\n\")\n",
    "\n",
    "# Print number of individual files processed\n",
    "num_files_processed = len([result for result in WER_results if isinstance(result, dict)])\n",
    "print(f\"Number of individual files processed: {num_files_processed}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T14:52:50.777166Z",
     "iopub.status.busy": "2024-06-16T14:52:50.777166Z",
     "iopub.status.idle": "2024-06-16T14:52:51.856503Z",
     "shell.execute_reply": "2024-06-16T14:52:51.856503Z",
     "shell.execute_reply.started": "2024-06-16T14:52:50.777166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot: D:\\ASR\\ParlaspeechHR\\wav2vec2-large-slavih-hr\\wav2vec2-large-slavic-parlaspeech-hr\\WER_results_v3.3.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize lists to store the number of files processed and the corresponding WER values\n",
    "num_files_processed = []\n",
    "wer_values = []\n",
    "\n",
    "# Iterate over the number of files processed\n",
    "for i in range(1, len(WER_results) + 1):\n",
    "    # Calculate overall totals for the first i files\n",
    "    overall_total_asr_deletions = sum(result.get(\"asr_deletions\", 0) for result in WER_results[:i] if isinstance(result, dict))\n",
    "    overall_total_asr_additions = sum(result.get(\"asr_additions\", 0) for result in WER_results[:i] if isinstance(result, dict))\n",
    "    overall_total_asr_substitutions = sum(result.get(\"asr_substitutions\", 0) for result in WER_results[:i] if isinstance(result, dict))\n",
    "    overall_total_tokens = sum(result.get(\"tokens\", 0) for result in WER_results[:i] if isinstance(result, dict))\n",
    "    \n",
    "    # Calculate WER\n",
    "    if overall_total_tokens > 0:\n",
    "        wer = (overall_total_asr_deletions + overall_total_asr_additions + overall_total_asr_substitutions) / overall_total_tokens\n",
    "    else:\n",
    "        wer = 0\n",
    "    \n",
    "    # Append the number of files processed and the WER value to the lists\n",
    "    num_files_processed.append(i)\n",
    "    wer_values.append(wer)\n",
    "\n",
    "# Define a function to calculate the moving average\n",
    "def moving_average(values, window):\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    sma = np.convolve(values, weights, 'valid')\n",
    "    return sma\n",
    "\n",
    "# Calculate the moving average of the WER values with a window size\n",
    "window_size = 100  # Adjust this value as needed\n",
    "smoothed_wer_values = moving_average(wer_values, window_size)\n",
    "\n",
    "# Adjust the num_files_processed to match the length of the smoothed WER values\n",
    "adjusted_num_files_processed = num_files_processed[window_size-1:]\n",
    "\n",
    "# Plot the WER values and the smoothed WER values\n",
    "plt.figure(figsize=(10, 6))\n",
    "#plt.plot(num_files_processed, wer_values, marker='o', linestyle='-', color='b', alpha=0.3, label='Original WER')\n",
    "plt.plot(adjusted_num_files_processed, smoothed_wer_values, marker='o', linestyle='-', color='r', label='Smoothed WER')\n",
    "plt.xlabel('Number of Files Processed')\n",
    "plt.ylabel('Word Error Rate (WER)')\n",
    "plt.title('WER Variation with Number of Files Processed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Add text at the bottom of the plot\n",
    "\n",
    "\n",
    "wer_plot_from_version2 = wer_plot_from_version[:-4] + \"png\"\n",
    "\n",
    "wer_plot_save = os.path.join(wer_plot_save_path, wer_plot_from_version2)\n",
    "\n",
    "bottom_text = f\"Source dict: {wer_plot_from_version[:-4]} Code work version:{work_version}. Smoothed window size: {window_size}.\"\n",
    "plt.figtext(0.5, 0.001, bottom_text, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "plt.savefig(wer_plot_save, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saving plot: {wer_plot_save}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results WER_results_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T17:05:06.463417Z",
     "iopub.status.busy": "2024-06-16T17:05:06.463417Z",
     "iopub.status.idle": "2024-06-16T17:05:06.468728Z",
     "shell.execute_reply": "2024-06-16T17:05:06.468728Z",
     "shell.execute_reply.started": "2024-06-16T17:05:06.463417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Total ASR Deletions (LM): 0\n",
      "Overall Total ASR Additions (LM): 0\n",
      "Overall Total ASR Substitutions (LM): 0\n",
      "Overall Total Original Tokens (LM): 0\n",
      "\n",
      "Overall Word Error Rate (WER) for LM: 0.0000\n",
      "\n",
      "Number of individual files processed for LM: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall totals across all runs for LM results\n",
    "overall_total_asr_deletions_LM = sum(result.get(\"asr_deletions\", 0) for result in WER_results_LM if isinstance(result, dict))\n",
    "overall_total_asr_additions_LM = sum(result.get(\"asr_additions\", 0) for result in WER_results_LM if isinstance(result, dict))\n",
    "overall_total_asr_substitutions_LM = sum(result.get(\"asr_substitutions\", 0) for result in WER_results_LM if isinstance(result, dict))\n",
    "overall_total_tokens_LM = sum(result.get(\"tokens\", 0) for result in WER_results_LM if isinstance(result, dict))\n",
    "\n",
    "# Calculate overall error rate for LM results\n",
    "total_files_with_error_rate_LM = sum(1 for result in WER_results_LM if isinstance(result, dict) and \"error_rate\" in result)\n",
    "overall_total_error_rate_LM = sum(result[\"error_rate\"] for result in WER_results_LM if isinstance(result, dict) and \"error_rate\" in result) / total_files_with_error_rate_LM if total_files_with_error_rate_LM > 0 else 0\n",
    "\n",
    "# Print overall totals including substitutions for LM results\n",
    "print(f\"Overall Total ASR Deletions (LM): {overall_total_asr_deletions_LM}\")\n",
    "print(f\"Overall Total ASR Additions (LM): {overall_total_asr_additions_LM}\")\n",
    "print(f\"Overall Total ASR Substitutions (LM): {overall_total_asr_substitutions_LM}\")\n",
    "print(f\"Overall Total Original Tokens (LM): {overall_total_tokens_LM}\\n\")\n",
    "\n",
    "# Calculate WER for LM results\n",
    "wer_LM = (overall_total_asr_deletions_LM + overall_total_asr_additions_LM + overall_total_asr_substitutions_LM) / overall_total_tokens_LM if overall_total_tokens_LM > 0 else 0\n",
    "\n",
    "# Print WER for LM results\n",
    "print(f\"Overall Word Error Rate (WER) for LM: {wer_LM:.4f}\\n\")\n",
    "\n",
    "# Print number of individual files processed for LM results\n",
    "num_files_processed_LM = len([result for result in WER_results_LM if isinstance(result, dict)])\n",
    "print(f\"Number of individual files processed for LM: {num_files_processed_LM}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run WER matchin BATCH -- KINDA BUSTED EH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T14:55:20.264817Z",
     "iopub.status.busy": "2024-06-16T14:55:20.264817Z",
     "iopub.status.idle": "2024-06-16T14:55:20.267172Z",
     "shell.execute_reply": "2024-06-16T14:55:20.267172Z",
     "shell.execute_reply.started": "2024-06-16T14:55:20.264817Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_printing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T14:55:20.463819Z",
     "iopub.status.busy": "2024-06-16T14:55:20.463819Z",
     "iopub.status.idle": "2024-06-16T14:55:20.468368Z",
     "shell.execute_reply": "2024-06-16T14:55:20.468368Z",
     "shell.execute_reply.started": "2024-06-16T14:55:20.463819Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_list, target_sr=16000):\n",
    "        self.file_list = file_list\n",
    "        self.target_sr = target_sr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_file = self.file_list[idx]\n",
    "        speech, sample_rate = torchaudio.load(input_file)\n",
    "        if sample_rate != self.target_sr:\n",
    "            resampler = Resample(orig_freq=sample_rate, new_freq=self.target_sr)\n",
    "            speech = resampler(speech)\n",
    "        return speech.squeeze(0), self.target_sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T15:04:25.808164Z",
     "iopub.status.busy": "2024-06-16T15:04:25.808164Z",
     "iopub.status.idle": "2024-06-16T15:04:25.817220Z",
     "shell.execute_reply": "2024-06-16T15:04:25.817220Z",
     "shell.execute_reply.started": "2024-06-16T15:04:25.808164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching online.\n"
     ]
    }
   ],
   "source": [
    "### DEFINING BATCH PROCESSING ####\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def process_transcribe_batch(batch, target_sr=16000, device=device, debug_printing=debug_printing):\n",
    "    all_speech = []\n",
    "\n",
    "    # Load and resample all audio files in the batch\n",
    "    for input_file, transcription in batch:\n",
    "        \n",
    "        speech, sample_rate = torchaudio.load(filename)\n",
    "        \n",
    "        if sample_rate != target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
    "            speech = resampler(speech)\n",
    "            \n",
    "        all_speech.append(speech)\n",
    "\n",
    "        # Pad sequences to the same length\n",
    "        max_length = max(s.shape[1] for s in all_speech)\n",
    "        padded_speech = [torch.nn.functional.pad(s, (0, max_length - s.shape[1])) for s in all_speech]\n",
    "    \n",
    "        # Stack all padded speech into a single tensor\n",
    "        input_values = torch.stack(padded_speech).squeeze(1).to(device)\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"input_values.shape:\", input_values.shape)\n",
    "    \n",
    "        # Process the batch with the processor\n",
    "        input_values = processor0(input_values, sampling_rate=target_sr, return_tensors=\"pt\").input_values.to(device)\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"input_values.shape after processor:\", input_values.shape)\n",
    "    \n",
    "        # Fix batches shape\n",
    "        input_values = input_values.squeeze(0)\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"input_values.shape after remix:\", input_values.shape)\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.inference_mode():\n",
    "            logits = model0(input_values).logits\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"Logits shape:\", logits.shape)\n",
    "    \n",
    "        # Get the predicted token IDs (greedy decoding)\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"Predicted IDs shape:\", predicted_ids.shape)\n",
    "    \n",
    "        # Convert predicted IDs to numpy array\n",
    "        predicted_ids = predicted_ids.cpu().numpy()\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"Predicted IDs (numpy):\", predicted_ids)\n",
    "    \n",
    "        # Decode the predicted IDs\n",
    "        transcriptions = processor0.batch_decode(predicted_ids)\n",
    "    \n",
    "        if debug_printing:\n",
    "            print(\"Transcriptions:\", transcriptions)\n",
    "    \n",
    "        return transcriptions\n",
    "\n",
    "# Function to process a single file's transcription\n",
    "def process_file(input_file):\n",
    "    # Retrieve original transcription from dictionary\n",
    "    original_transcription = ' '.join(audio_transcriptions[input_file])\n",
    "    \n",
    "    # Tokenize original and ASR transcriptions\n",
    "    original_tokens = tokenize_text(original_transcription)\n",
    "    asr_tokens = tokenize_text(process_transcribe_batch([input_file], target_sr=16000, device=device)[0])  # Process single file\n",
    "\n",
    "    # Normalize ASR tokens\n",
    "    normalized_asr_tokens = normalize_numbers(asr_tokens, norm_nums)\n",
    "\n",
    "    # Align ASR tokens with original tokens based on character similarity\n",
    "    aligned_asr_tokens = align_tokens(original_tokens, normalized_asr_tokens, similarity_threshold=similarity_threshold)\n",
    "\n",
    "    # Calculate error metrics\n",
    "    asr_deletion = len(original_tokens) - len(aligned_asr_tokens)\n",
    "    asr_addition = len(normalized_asr_tokens) - len(aligned_asr_tokens)\n",
    "\n",
    "    substitutions = sum(1 for orig_token, asr_token in zip(original_tokens, aligned_asr_tokens) if orig_token != asr_token)\n",
    "\n",
    "    total_tokens = len(original_tokens)\n",
    "    error_rate = (asr_deletion + asr_addition + substitutions) / total_tokens\n",
    "\n",
    "    # Prepare file result\n",
    "    file_result = {\n",
    "        \"input_file\": input_file,\n",
    "        \"tokens\": total_tokens,\n",
    "        \"asr_deletions\": asr_deletion,\n",
    "        \"asr_additions\": asr_addition,\n",
    "        \"asr_substitutions\": substitutions,\n",
    "        \"error_rate\": error_rate\n",
    "    }\n",
    "\n",
    "    return file_result\n",
    "\n",
    "\n",
    "print(\"Batching online.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T15:04:26.023431Z",
     "iopub.status.busy": "2024-06-16T15:04:26.023431Z",
     "iopub.status.idle": "2024-06-16T15:04:26.026038Z",
     "shell.execute_reply": "2024-06-16T15:04:26.026038Z",
     "shell.execute_reply.started": "2024-06-16T15:04:26.023431Z"
    }
   },
   "outputs": [],
   "source": [
    "WER_results_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T15:04:26.247051Z",
     "iopub.status.busy": "2024-06-16T15:04:26.247051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 1:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Number of CPU cores\n",
    "num_processes = cpu_count()\n",
    "print(f\"Number of CPU cores: {num_processes}\")\n",
    "\n",
    "num_runs = 2  # Number of runs to average over, each time picking anew randoms\n",
    "batch_size = num_processes  # Number of files to process per batch\n",
    "max_files_to_process = 20  # Adjust this as needed\n",
    "\n",
    "transcription_list = list(audio_transcriptions.keys())  # Assuming audio_transcriptions is a dictionary with file paths\n",
    "shuffle_transcript = True  # Ensure shuffle_transcript is defined\n",
    "\n",
    "# Iterate over each run\n",
    "for run in range(num_runs):\n",
    "    total_asr_deletions = 0\n",
    "    total_asr_additions = 0\n",
    "    total_asr_substitutions = 0\n",
    "    total_tokens = 0\n",
    "    total_error_rate = 0.0\n",
    "    n = 0  # Number of files processed\n",
    "    \n",
    "    # Shuffle the transcription list for each run if needed\n",
    "    if shuffle_transcript:\n",
    "        random.shuffle(transcription_list)\n",
    "    \n",
    "    # Process in batches using multiprocessing\n",
    "    with Pool(num_processes) as pool:\n",
    "        # Split transcription_list into chunks of batch_size\n",
    "        batches = [transcription_list[i:i + batch_size] for i in range(0, min(max_files_to_process, len(transcription_list)), batch_size)]\n",
    "        \n",
    "        # Process each batch asynchronously\n",
    "        with tqdm(total=len(batches), desc=f\"Run {run+1}\") as pbar:\n",
    "            for batch in batches:\n",
    "                # Process batch asynchronously\n",
    "                batch_results = pool.map(process_file, batch)\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Accumulate results and calculate metrics for this batch\n",
    "                for result in batch_results:\n",
    "                    total_asr_deletions += result[\"asr_deletions\"]\n",
    "                    total_asr_additions += result[\"asr_additions\"]\n",
    "                    total_asr_substitutions += result[\"asr_substitutions\"]\n",
    "                    total_tokens += result[\"tokens\"]\n",
    "                    total_error_rate += result[\"error_rate\"]\n",
    "                    n += 1  # Increment file counter\n",
    "    \n",
    "    # Calculate average error metrics for this run\n",
    "    if n > 0:\n",
    "        average_asr_deletions = total_asr_deletions / n\n",
    "        average_asr_additions = total_asr_additions / n\n",
    "        average_asr_substitutions = total_asr_substitutions / n\n",
    "        average_error_rate = total_error_rate / n\n",
    "    else:\n",
    "        average_asr_deletions = 0\n",
    "        average_asr_additions = 0\n",
    "        average_asr_substitutions = 0\n",
    "        average_error_rate = 0.0\n",
    "    \n",
    "    # Print or use the average error metrics for the run as needed\n",
    "    print(f\"Average ASR Deletions: {average_asr_deletions}\")\n",
    "    print(f\"Average ASR Additions: {average_asr_additions}\")\n",
    "    print(f\"Average ASR Substitutions: {average_asr_substitutions}\")\n",
    "    print(f\"Average Error Rate (WER): {average_error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x scrap later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = cpu_count()  # Number of CPU cores\n",
    "print(num_processes)\n",
    "\n",
    "num_runs = 2  # Number of runs to average over, each time picking anew randoms\n",
    "batch_size = num_processes  # Number of files to process per batch\n",
    "max_files_to_process = 20  # Adjust this as needed\n",
    "\n",
    "transcription_list = list(audio_transcriptions.items())  # Assume audio_transcriptions is defined somewhere\n",
    "shuffle_transcript = True  # Ensure shuffle_transcript is defined\n",
    "\n",
    "# Iterate over each run\n",
    "for run in range(num_runs):\n",
    "    total_asr_deletions = 0\n",
    "    total_asr_additions = 0\n",
    "    total_asr_substitutions = 0\n",
    "    total_tokens = 0\n",
    "    total_error_rate = 0.0\n",
    "    n = 0  # Number of files processed\n",
    "    \n",
    "    # Shuffle the transcription list for each run if needed\n",
    "    if shuffle_transcript:\n",
    "        random.shuffle(transcription_list)\n",
    "    \n",
    "    # Process in batches using multiprocessing\n",
    "    with Pool(num_processes) as pool:\n",
    "        # Split transcription_list into chunks of batch_size\n",
    "        batches = [transcription_list[i:i + batch_size] for i in range(0, min(max_files_to_process, len(transcription_list)), batch_size)]\n",
    "        \n",
    "        # Process each batch asynchronously\n",
    "        with tqdm(total=len(batches), desc=f\"Run {run+1}\") as pbar:\n",
    "            for result in pool.imap_unordered(process_transcribe_batch, batches):\n",
    "                for j, (input_file, original_transcription) in enumerate(batches[n]):\n",
    "                    tekst = result[j]\n",
    "                    \n",
    "                    # Get original transcription from dictionary\n",
    "                    original_transcription = ' '.join(audio_transcriptions[input_file])\n",
    "                    \n",
    "                    # Tokenize both transcriptions\n",
    "                    original_tokens = tokenize_text(original_transcription)\n",
    "                    asr_tokens = tokenize_text(tekst)\n",
    "                \n",
    "                    # Normalize numbers in ASR tokens\n",
    "                    normalized_asr_tokens = normalize_numbers(asr_tokens, norm_nums)\n",
    "                \n",
    "                    # Align ASR tokens with original tokens based on character similarity\n",
    "                    aligned_asr_tokens = align_tokens(original_tokens, normalized_asr_tokens, similarity_threshold=similarity_threshold)\n",
    "                \n",
    "                    # Calculate error metrics\n",
    "                    asr_deletion = len(original_tokens) - len(aligned_asr_tokens)\n",
    "                    asr_addition = len(normalized_asr_tokens) - len(aligned_asr_tokens)\n",
    "                    \n",
    "                    # Calculate substitutions between original and aligned ASR tokens\n",
    "                    substitutions = 0\n",
    "                    for orig_token, asr_token in zip(original_tokens, aligned_asr_tokens):\n",
    "                        if orig_token != asr_token:\n",
    "                            substitutions += 1\n",
    "                    \n",
    "                    total_asr_substitutions += substitutions\n",
    "                    total_tokens = len(original_tokens)\n",
    "                    error_rate = (asr_deletion + asr_addition + substitutions) / total_tokens\n",
    "                \n",
    "                    # Accumulate metrics\n",
    "                    total_asr_deletions += asr_deletion\n",
    "                    total_asr_additions += asr_addition\n",
    "                    total_error_rate += error_rate\n",
    "                    n += 1\n",
    "        \n",
    "                    # Store individual file results for this run including substitutions\n",
    "                    file_result = {\n",
    "                        \"input_file\": input_file,\n",
    "                        \"tokens\": total_tokens,\n",
    "                        \"asr_deletions\": asr_deletion,\n",
    "                        \"asr_additions\": asr_addition,\n",
    "                        \"asr_substitutions\": substitutions,\n",
    "                        \"error_rate\": error_rate\n",
    "                    }\n",
    "                    \n",
    "                    # Update tqdm progress bar\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # Print or use the error metric for each file as needed\n",
    "                    if debug_printing:\n",
    "                        print(f\"Transcription {n}: {tekst}\")\n",
    "                        print(f\"original_tokens: \\n{original_tokens}\\n\")\n",
    "                        print(f\"asr_tokens: \\n{asr_tokens}\\n\")\n",
    "                        print(f\"normalized_asr_tokens: \\n{normalized_asr_tokens}\\n\")\n",
    "                        print(f\"aligned_asr_tokens: \\n{aligned_asr_tokens}\\n\")\n",
    "                        print(f\"ASR Deletions: {asr_deletion}\")\n",
    "                        print(f\"ASR Additions: {asr_addition}\")\n",
    "                        print(f\"Total Tokens: {len(original_tokens)}\")\n",
    "                        print(f\"Error Rate (WER): {error_rate}\\n\")\n",
    "\n",
    "# Calculate average error metrics for this run\n",
    "average_asr_deletions = total_asr_deletions / n\n",
    "average_asr_additions = total_asr_additions / n\n",
    "average_asr_substitutions = total_asr_substitutions / n\n",
    "average_error_rate = total_error_rate / n\n",
    "\n",
    "# Print or use the average error metrics for the run as needed\n",
    "print(f\"Average ASR Deletions: {average_asr_deletions}\")\n",
    "print(f\"Average ASR Additions: {average_asr_additions}\")\n",
    "print(f\"Average ASR Substitutions: {average_asr_substitutions}\")\n",
    "print(f\"Average Error Rate (WER): {average_error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PRIMJER normalize_number POBOLJANJE WER\n",
    "15 lip 2024 21:14h\n",
    "\n",
    "original_tokens: \n",
    "['i', 'bit', 'u', 'malo', 'neskroman', 'vi', 'mi', 'to', 'neete', 'zamjeriti', 'mi', 'smo', 'pokazali', 'da', 'moemo', 'kao', 'manja', 'drava', 'potaknuti', 'kolege', 'da', 'se', 'promjene', 'kriteriji', 'u', 'poglavlju', 'dvadeset', 'tri']\n",
    "\n",
    "asr_tokens: \n",
    "['i', 'bit', 'e', 'malo', 'neshroman', 'i', 'mi', 'to', 'neete', 'zamjeriti', 'mi', 'smo', 'pokazali', 'da', 'moemo', 'kao', 'manja', 'drava', 'potaknuti', 'kolege', 'da', 'se', 'promijene', 'kriteriji', 'u', 'poglavlju', '23']\n",
    "\n",
    "normalized_asr_tokens: \n",
    "['i', 'bit', 'e', 'malo', 'neshroman', 'i', 'mi', 'to', 'neete', 'zamjeriti', 'mi', 'smo', 'pokazali', 'da', 'moemo', 'kao', 'manja', 'drava', 'potaknuti', 'kolege', 'da', 'se', 'promijene', 'kriteriji', 'u', 'poglavlju', 'dvadeset', 'tri']\n",
    "\n",
    "aligned_asr_tokens: \n",
    "['i', 'bit', 'e', 'malo', 'neshroman', 'i', 'mi', 'to', 'neete', 'zamjeriti', 'mi', 'smo', 'pokazali', 'da', 'moemo', 'kao', 'manja', 'drava', 'potaknuti', 'kolege', 'da', 'se', 'promijene', 'kriteriji', 'u', 'poglavlju', 'dvadeset', 'tri']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:04:14.696510Z",
     "iopub.status.busy": "2024-06-15T14:04:14.696510Z",
     "iopub.status.idle": "2024-06-15T14:04:14.699823Z",
     "shell.execute_reply": "2024-06-15T14:04:14.699823Z",
     "shell.execute_reply.started": "2024-06-15T14:04:14.696510Z"
    }
   },
   "source": [
    "WORKING WITH v3.0 ## BOTH W and W/out LM WORKING\n",
    "CHECKED 15 lip 2024 17:45h\n",
    "\n",
    "VERSIONS OF PYTORCH\n",
    "\n",
    "Name: torch\n",
    "Version: 2.1.2\n",
    "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
    "Home-page: https://pytorch.org/\n",
    "Author: PyTorch Team\n",
    "Author-email: packages@pytorch.org\n",
    "License: BSD-3\n",
    "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
    "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
    "Required-by: accelerate, optimum, sentence-transformers, torchaudio, torchvision\n",
    "WARNING: Skipping C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\pandas-2.1.4.dist-info due to invalid metadata entry 'name'\n",
    "Name: torchvision\n",
    "Version: 0.16.2\n",
    "Summary: image and video datasets and models for torch deep learning\n",
    "Home-page: https://github.com/pytorch/vision\n",
    "Author: PyTorch Core Team\n",
    "Author-email: soumith@pytorch.org\n",
    "License: BSD\n",
    "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
    "Requires: numpy, pillow, requests, torch\n",
    "Required-by: sentence-transformers\n",
    "WARNING: Skipping C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\\pandas-2.1.4.dist-info due to invalid metadata entry 'name'\n",
    "Name: torchaudio\n",
    "Version: 2.3.1\n",
    "Summary: An audio package for PyTorch\n",
    "Home-page: https://github.com/pytorch/audio\n",
    "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
    "Author-email: soumith@pytorch.org\n",
    "License: \n",
    "Location: C:\\Users\\Public\\anaconda3\\envs\\PyPhon\\Lib\\site-packages\n",
    "Requires: torch\n",
    "Required-by: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3uz19EkBaZsrjq2rN6rV0",
   "provenance": [
    {
     "file_id": "1T9A_vTHdaB2oOuRCRRwTTAHs1379J-6l",
     "timestamp": 1718361648667
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
