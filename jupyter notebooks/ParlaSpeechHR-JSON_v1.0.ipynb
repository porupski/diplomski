{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfce36-99ff-44e1-89cc-df06f22566c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "613f829a-90de-4b72-ab5b-6db7ac9c0a4c",
   "metadata": {},
   "source": [
    "## Priprema ParlaSpeechHR .json filea za obradu:\n",
    "\n",
    "* DIPL.FON: frekvencija glasnika\n",
    "* JKIM: spomen mladih, studenata, djece\n",
    "* STAT: seminar neš idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac945fe-9a78-4577-a196-c63080df1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ea25e5-7767-486a-b704-caa87bbf9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import jsonlines\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba6d3c8-e5ef-45b2-b909-e66390465701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL normalized ASCII and loaded!\n",
      "Sorting data by: utterance_id_start\n",
      "Sorted data by: utterance_id_start\n",
      "saved as CSV\n"
     ]
    }
   ],
   "source": [
    "# # Decoding unicode to Latin\n",
    "# def normalize_words(words_list):\n",
    "#     return [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8') for word in words_list]\n",
    "\n",
    "\n",
    "# # Read the JSON Lines file\n",
    "# data = []\n",
    "# with jsonlines.open('ParlaSpeech-HR.v1.0.jsonl', 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Normalize specific fields to ASCII (change 'field_to_normalize' accordingly)\n",
    "#         line['words'] = normalize_words(line['words'])\n",
    "#         data.append(line)\n",
    "        \n",
    "# print(\"JSONL normalized ASCII and loaded!\")\n",
    "\n",
    "# print(f\"Sorting data by: utterance_id_start\")\n",
    "# # Sort the data by a specific field (e.g., 'utterance_id_start')\n",
    "# sorted_data = sorted(data, key=lambda x: (x.get('orig_file'), x.get('utterance_id_start'), x.get('start')))\n",
    "# print(f\"Sorted data by: utterance_id_start\")\n",
    "\n",
    "# # Convert the sorted data to a DataFrame (optional but useful)\n",
    "# df = pd.DataFrame(sorted_data)\n",
    "\n",
    "# # Save as CSV\n",
    "# df.to_csv('sorted_ParlaSpeech-HR.v1.0.csv', index=False)\n",
    "# print(\"saved as CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ac8a4e-12c6-4380-a91c-f717aaf9da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for specific character replacements\n",
    "unicode_mapping = {\n",
    "    '\\u0161': 'š',  # š\n",
    "    '\\u017e': 'ž',  # ž\n",
    "    '\\u010d': 'č',  # č\n",
    "    '\\u0111': 'đ',  # đ\n",
    "    '\\u0107': 'ć'   # ć\n",
    "}\n",
    "\n",
    "# Function to normalize words using the mapping dictionary\n",
    "def normalize_words(words_list):\n",
    "    normalized_words = []\n",
    "    for word in words_list:\n",
    "        normalized_word = ''.join(unicode_mapping.get(char, char) for char in word)\n",
    "        normalized_words.append(normalized_word)\n",
    "    return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd080e-0265-4fd4-a1f7-c3e834534121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the JSON Lines file\n",
    "# print(\"Loading JSONL file\")\n",
    "# data = []\n",
    "# with jsonlines.open('ParlaSpeech-HR.v1.0.jsonl', 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Normalize the list of words in the 'words' field using the mapping dictionary\n",
    "#         line['words'] = normalize_words(line['words'])\n",
    "#         data.append(line)\n",
    "\n",
    "# print(\"Sorting by orig_file, utterance_id_start and start...\")\n",
    "# # Sort the data by a specific field (e.g., 'utterance_id_start')\n",
    "# sorted_data = sorted(data, key=lambda x: (x.get('orig_file'), x.get('utterance_id_start'), x.get('start')))\n",
    "\n",
    "# # Convert the sorted data to a DataFrame (optional but useful)\n",
    "# df = pd.DataFrame(sorted_data)\n",
    "\n",
    "\n",
    "# columns_to_drop = ['word_start_times',\n",
    "#                    'utterance_id_end',\n",
    "#                    'norm_words_start_times',\n",
    "#                    'norm_words',\n",
    "#                    'end',\n",
    "#                    'split',\n",
    "#                    'norm_words_edited',\n",
    "#                    'path',\n",
    "#                    'utterance_id_start']\n",
    "# print(f\"Dropping columns: {columns_to_drop}\")\n",
    "\n",
    "# # Drop specified columns from the DataFrame\n",
    "# df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# # Save as CSV\n",
    "# df.to_csv('sorted_ParlaSpeech-HR.v1.1.csv', index=False)\n",
    "# print(\"Saved as .CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6706dd76-bf1e-4f3a-b75a-50203b00b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSONL file\n",
      "Sorting by orig_file, utterance_id_start and start...\n",
      "Dropping columns: ['word_start_times', 'utterance_id_end', 'norm_words_start_times', 'norm_words', 'end', 'split', 'norm_words_edited']\n",
      "Saved as .CSV!\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON Lines file\n",
    "\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "# Function to replace specific Unicode characters in words_list\n",
    "def replace_unicode_chars(words_list):\n",
    "    replacements = {\n",
    "        '\\u0161': 'š',  # š\n",
    "        '\\u017e': 'ž',  # ž\n",
    "        '\\u010d': 'č',  # č\n",
    "        '\\u0111': 'đ',  # đ\n",
    "        '\\u0107': 'ć'   # ć\n",
    "    }\n",
    "    return [\"\".join(replacements.get(char, char) for char in word) for word in words_list]\n",
    "    \n",
    "print(\"Loading JSONL file\")\n",
    "# Read the JSON Lines file and process the data\n",
    "data = []\n",
    "with codecs.open('ParlaSpeech-HR.v1.0.jsonl', 'r', encoding='utf-8') as file:\n",
    "    reader = jsonlines.Reader(file)\n",
    "    for line in reader:\n",
    "        line['words'] = replace_unicode_chars(line['words'])\n",
    "        data.append(line)\n",
    "\n",
    "print(\"Sorting by orig_file, utterance_id_start and start...\")\n",
    "# Sort the data by a specific field (e.g., 'utterance_id_start')\n",
    "sorted_data = sorted(data, key=lambda x: (x.get('orig_file'), x.get('utterance_id_start'), x.get('start')))\n",
    "\n",
    "# Convert the sorted data to a DataFrame (optional but useful)\n",
    "df = pd.DataFrame(sorted_data)\n",
    "\n",
    "\n",
    "columns_to_drop = ['word_start_times',\n",
    "                   'utterance_id_end',\n",
    "                   'norm_words_start_times',\n",
    "                   'norm_words',\n",
    "                   'end',\n",
    "                   'split',\n",
    "                   'norm_words_edited',\n",
    "                  # 'path',\n",
    "                  # 'utterance_id_start'\n",
    "                  ]\n",
    "print(f\"Dropping columns: {columns_to_drop}\")\n",
    "\n",
    "# Drop specified columns from the DataFrame\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv('sorted_ParlaSpeech-HR.v1.1.csv', index=False)\n",
    "print(\"Saved as .CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5d0fbaf-921c-4d14-9040-c0b6e1df58b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         konačni prijedlog zakona o izmjenama i dopunam...\n",
      "1         u svezi sa člankom 190. poslovnika hrvatskog s...\n",
      "2         za zakonodavstvo i odbor za financije i državn...\n",
      "3         hvala lijepo gospodine potpredsjedniče hrvatsk...\n",
      "4         zakona o izmjenama i dopunama zakona o doprino...\n",
      "                                ...                        \n",
      "403920    hrvatski narod direktno odlučuje, a kad se rad...\n",
      "403921    naše domovine andrej plenković koji je neuspje...\n",
      "403922                  zanima me hoće li andrej plenković,\n",
      "403923    znači po pitanju novog zakona o referendumima ...\n",
      "403924    pa ćemo mi se često ugledati na zemlje zapadne...\n",
      "Name: sentence, Length: 403925, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "# Join the lists of words into a single sentence in a new column 'sentence'\n",
    "df_copy['sentence'] = df_copy['words'].apply(lambda x: ' '.join(x)).str.lower()\n",
    "\n",
    "# Drop the original 'words' column if not needed anymore\n",
    "df_copy.drop(columns='words', inplace=True)\n",
    "\n",
    "print(df_copy['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fec6fc9-82fc-4934-a934-b708ea92a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         lijepo. kolegice i kolege, nemojte se vi varda...\n",
      "1         hdz želi pokušati dati obećanje za 6 mjeseci d...\n",
      "2         ste imali rast 3%, a sada predlaže kao fol, g....\n",
      "3         ma dajte molim vas, to nitko ne vjeruje, to ne...\n",
      "4         djeca mogu stjecati znanje i obrazovati se. da...\n",
      "                                ...                        \n",
      "403920    prosječna plaća u hrvatskoj, svijež podatak ne...\n",
      "403921    krenuti ću na onom dijelu gdje se opisuju poje...\n",
      "403922    poznavanje niza propisa da bi uopće mogao polo...\n",
      "403923    pa konkretno i nekih drugih stvari, drugih zak...\n",
      "403924    tako da prije svega, moramo, htio bi na taj na...\n",
      "Name: sentence, Length: 403925, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Group by 'orig_file' and aggregate 'sentence' into a single text chunk\n",
    "df_combined = df_copy.groupby('path')['sentence'].apply(' '.join).reset_index()\n",
    "print(df_combined['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6650ac8-bd2e-4e02-9a39-66a090959d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as .CSV!\n"
     ]
    }
   ],
   "source": [
    "# Save as CSV\n",
    "df_combined.to_csv('blokovi_tekstova_ParlaSpeech-HR.v1.1.csv', index=False)\n",
    "print(\"Saved as .CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc40874e-a71b-4f84-a63e-5fa6de01e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' ': 14419033, 'a': 8473320, 'o': 7134726, 'i': 7050533, 'e': 6080196, 'n': 4648748, 't': 3651668, 'r': 3511665, 'j': 3419250, 's': 3255595, 'd': 2834497, 'u': 2828080, 'v': 2702877, 'm': 2543126, 'k': 2461565, 'l': 2239951, 'p': 2027631, 'z': 1281364, 'g': 1117595, ',': 966159, 'b': 952252, 'š': 681802, '.': 633399, 'č': 565108, 'h': 519356, 'c': 512317, 'ć': 477359, 'ž': 410163, 'đ': 163320, 'f': 122684, '0': 121397, '1': 73991, '2': 69318, '-': 60284, '5': 36839, '?': 34026, '3': 32637, '4': 23869, '6': 21275, '7': 20024, '8': 18816, '%': 18226, '9': 17383, \"'\": 4564, '_': 3838, '„': 3129, '“': 3083, 'x': 2429, '/': 1820, ':': 1656, 'w': 1581, 'y': 1202, '!': 416, ')': 352, '(': 258, '+': 238, 'q': 134, ';': 77, '\"': 41, 'ü': 39, '¾': 35, '&': 26, '–': 22, '¼': 22, '>': 10, '—': 10, '@': 10, '’': 8, 'ö': 7, '̊': 6, '=': 4, '#': 4, '¸': 3, 'ӧ': 3, '‰': 3, '*': 2, '€': 2, 'ä': 2, '°': 1, '½': 1, '´': 1, '′': 1, 'ô': 1, 'ţ': 1, 'π': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Concatenate all sentences into a single string\n",
    "all_text = ' '.join(df_combined['sentence'])\n",
    "\n",
    "# Count the frequency of each character\n",
    "character_frequency = Counter(all_text.lower())  # Convert to lowercase for uniform counting\n",
    "\n",
    "# Display the character frequencies\n",
    "print(character_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f810972-465a-4793-ae8f-15e609455133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 8473320, 'b': 952252, 'c': 512317, 'č': 565108, 'ć': 477359, 'd': 2834497, 'đ': 163320, 'e': 6080196, 'f': 122684, 'g': 1117595, 'h': 519356, 'i': 7050533, 'j': 3419250, 'k': 2461565, 'l': 2239951, 'm': 2543126, 'n': 4648748, 'o': 7134726, 'p': 2027631, 'r': 3511665, 's': 3255595, 'š': 681802, 't': 3651668, 'u': 2828080, 'v': 2702877, 'z': 1281364, 'ž': 410163}\n"
     ]
    }
   ],
   "source": [
    "#abcčćdđefghijklmnoprsštuvzž\n",
    "# Your list of characters\n",
    "characters = list('abcčćdđefghijklmnoprsštuvzž')\n",
    "\n",
    "# Create a dictionary to hold character frequencies\n",
    "char_freq_dict = {char: character_frequency[char] for char in characters}\n",
    "\n",
    "# Display the character frequencies\n",
    "print(char_freq_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82599b75-5a52-47b0-a0ed-50520ffc9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'count': 8473320, 'freq%': 11.823}, 'b': {'count': 952252, 'freq%': 1.329}, 'c': {'count': 512317, 'freq%': 0.715}, 'č': {'count': 565108, 'freq%': 0.789}, 'ć': {'count': 477359, 'freq%': 0.666}, 'd': {'count': 2834497, 'freq%': 3.955}, 'đ': {'count': 163320, 'freq%': 0.228}, 'e': {'count': 6080196, 'freq%': 8.484}, 'f': {'count': 122684, 'freq%': 0.171}, 'g': {'count': 1117595, 'freq%': 1.559}, 'h': {'count': 519356, 'freq%': 0.725}, 'i': {'count': 7050533, 'freq%': 9.838}, 'j': {'count': 3419250, 'freq%': 4.771}, 'k': {'count': 2461565, 'freq%': 3.435}, 'l': {'count': 2239951, 'freq%': 3.126}, 'm': {'count': 2543126, 'freq%': 3.549}, 'n': {'count': 4648748, 'freq%': 6.487}, 'o': {'count': 7134726, 'freq%': 9.955}, 'p': {'count': 2027631, 'freq%': 2.829}, 'r': {'count': 3511665, 'freq%': 4.9}, 's': {'count': 3255595, 'freq%': 4.543}, 'š': {'count': 681802, 'freq%': 0.951}, 't': {'count': 3651668, 'freq%': 5.095}, 'u': {'count': 2828080, 'freq%': 3.946}, 'v': {'count': 2702877, 'freq%': 3.771}, 'z': {'count': 1281364, 'freq%': 1.788}, 'ž': {'count': 410163, 'freq%': 0.572}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total sum of frequencies\n",
    "total_sum = sum(char_freq_dict.values())\n",
    "\n",
    "# Merge counts and percentages into the same dictionary\n",
    "combined_dict = {char: {'count': freq, 'freq%': round((freq / total_sum) * 100, 3)} for char, freq in char_freq_dict.items()}\n",
    "\n",
    "# Display the combined dictionary\n",
    "print(combined_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a76718c-b29a-4804-8bfd-3ee9d2821aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'count': 8473320, 'freq%': 11.823}, 'o': {'count': 7134726, 'freq%': 9.955}, 'i': {'count': 7050533, 'freq%': 9.838}, 'e': {'count': 6080196, 'freq%': 8.484}, 'n': {'count': 4648748, 'freq%': 6.487}, 't': {'count': 3651668, 'freq%': 5.095}, 'r': {'count': 3511665, 'freq%': 4.9}, 'j': {'count': 3419250, 'freq%': 4.771}, 's': {'count': 3255595, 'freq%': 4.543}, 'd': {'count': 2834497, 'freq%': 3.955}, 'u': {'count': 2828080, 'freq%': 3.946}, 'v': {'count': 2702877, 'freq%': 3.771}, 'm': {'count': 2543126, 'freq%': 3.549}, 'k': {'count': 2461565, 'freq%': 3.435}, 'l': {'count': 2239951, 'freq%': 3.126}, 'p': {'count': 2027631, 'freq%': 2.829}, 'z': {'count': 1281364, 'freq%': 1.788}, 'g': {'count': 1117595, 'freq%': 1.559}, 'b': {'count': 952252, 'freq%': 1.329}, 'š': {'count': 681802, 'freq%': 0.951}, 'č': {'count': 565108, 'freq%': 0.789}, 'h': {'count': 519356, 'freq%': 0.725}, 'c': {'count': 512317, 'freq%': 0.715}, 'ć': {'count': 477359, 'freq%': 0.666}, 'ž': {'count': 410163, 'freq%': 0.572}, 'đ': {'count': 163320, 'freq%': 0.228}, 'f': {'count': 122684, 'freq%': 0.171}}\n"
     ]
    }
   ],
   "source": [
    "# Sort by highest percentage\n",
    "sorted_combined = dict(sorted(combined_dict.items(), key=lambda item: item[1]['freq%'], reverse=True))\n",
    "\n",
    "# Display the sorted dictionary by highest percentage\n",
    "print(sorted_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2b801c6-35b9-4080-bb8d-ba0f8c24380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Frekvencija_glasnika_ParlaSpeechHR_v1.0.csv' has been saved.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# File path to save the CSV\n",
    "file_path = 'Frekvencija_glasnika_ParlaSpeechHR_v1.0.csv'\n",
    "\n",
    "# Writing the sorted dictionary to a CSV file with UTF-8 encoding\n",
    "with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Character', 'Count', 'Freq%']  # Updated field names\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the data rows\n",
    "    for char, data in sorted_combined.items():\n",
    "        writer.writerow({'Character': char, 'Count': data['count'], 'Freq%': data['freq%']})\n",
    "\n",
    "print(f\"CSV file '{file_path}' has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2fcb0a79-0bc3-43e6-9398-2991e7f51d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the JSONL file: 14419034\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "# Path to your JSONL file\n",
    "jsonl_file_path = 'ParlaSpeech-HR.v1.0.jsonl'\n",
    "\n",
    "total_word_count = 0\n",
    "\n",
    "# Read the JSONL file and count words in each line\n",
    "with jsonlines.open(jsonl_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if 'words' in line:  # Check if 'words' field exists\n",
    "            words_list = line['words']  # Assuming 'words' is a list field in each JSON object\n",
    "            total_word_count += len(words_list)\n",
    "\n",
    "print(f\"Total number of words in the JSONL file: {total_word_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3435e7-a0c1-4ae1-bbe1-3c5f562b2ea2",
   "metadata": {},
   "source": [
    "# Frekvencije glasnika u ParlaSpeechHR-v1.0 (v1.0)\n",
    "\n",
    "Character,Count,Freq%\r\n",
    "a,8473320,11.823\r\n",
    "o,7134726,9.955\r\n",
    "i,7050533,9.838\r\n",
    "e,6080196,8.484\r\n",
    "n,4648748,6.487\r\n",
    "t,3651668,5.095\r\n",
    "r,3511665,4.9\r\n",
    "j,3419250,4.771\r\n",
    "s,3255595,4.543\r\n",
    "d,2834497,3.955\r\n",
    "u,2828080,3.946\r\n",
    "v,2702877,3.771\r\n",
    "m,2543126,3.549\r\n",
    "k,2461565,3.435\r\n",
    "l,2239951,3.126\r\n",
    "p,2027631,2.829\r\n",
    "z,1281364,1.788\r\n",
    "g,1117595,1.559\r\n",
    "b,952252,1.329\r\n",
    "š,681802,0.951\r\n",
    "č,565108,0.789\r\n",
    "h,519356,0.725\r\n",
    "c,512317,0.715\r\n",
    "ć,477359,0.666\r\n",
    "ž,410163,0.572\r\n",
    "đ,163320,0.228\r\n",
    "f,122684,0.171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c74e27-f13a-4c6b-8c50-726b0075f6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPhon",
   "language": "python",
   "name": "pyphon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
